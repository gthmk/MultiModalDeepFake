{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab59b3e-52de-48ae-9cd3-e6570dcfa62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from moviepy.editor import *\n",
    "\n",
    "def extract_audio(mp4_file_path, wav_file_path):\n",
    "    \"\"\"\n",
    "    Extract the audio from an MP4 file and save it as a WAV file.\n",
    "\n",
    "    Args:\n",
    "        mp4_file_path (str): The path to the MP4 file.\n",
    "        wav_file_path (str): The path to save the WAV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the video clip\n",
    "    video = VideoFileClip(mp4_file_path)\n",
    "\n",
    "    # Extract the audio\n",
    "    #audio = video.audio\n",
    "\n",
    "    # Set the audio codec to pcm_s16le\n",
    "    #audio.fps = 44100\n",
    "    #audio.codec = 'pcm_s16le'\n",
    "    \n",
    "    # Save the audio as a WAV file\n",
    "    video.audio.write_audiofile(wav_file_path)\n",
    "\n",
    "    # Close the video clip\n",
    "    video.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf7c41-e525-4203-847c-6ef2cb1811b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /home/ubuntu/data/demo/hany_206b_audio/206A-lecture01-05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ubuntu/data/demo/hany_206b_audio/206A-lecture02-01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ubuntu/data/demo/hany_206b_audio/206A-lecture01-03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ubuntu/data/demo/hany_206b_audio/206A-lecture01-04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in /home/ubuntu/data/demo/hany_206b_audio/206A-lecture02-02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "input_directory = '/home/ubuntu/data/demo/hany_206b_video'\n",
    "output_directory = '/home/ubuntu/data/demo/hany_206b_audio'\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith('.mp4'):\n",
    "        mp4_file_path = os.path.join(input_directory, filename)\n",
    "        wav_file_path = os.path.join(output_directory, filename[:-4] + '.wav')\n",
    "        extract_audio(mp4_file_path, wav_file_path)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b7598-6e26-4102-9716-bcd3c867d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "\n",
    "def split_audio(wav_file_path, output_dir, min_clip_length=7000, max_clip_length=12000):\n",
    "    \"\"\"\n",
    "    Split a WAV file into random audio clips of a specified length.\n",
    "\n",
    "    Args:\n",
    "        wav_file_path (str): The path to the WAV file to split.\n",
    "        output_dir (str): The directory to save the output audio clips in.\n",
    "        min_clip_length (int): The minimum length of each audio clip in milliseconds. Default is 7000.\n",
    "        max_clip_length (int): The maximum length of each audio clip in milliseconds. Default is 12000.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the WAV file\n",
    "    audio = AudioSegment.from_wav(wav_file_path)\n",
    "\n",
    "    # Calculate the duration of the audio in milliseconds\n",
    "    audio_length = len(audio)\n",
    "\n",
    "    # Generate a list of clip start times\n",
    "    clip_start_times = []\n",
    "    current_time = 0\n",
    "    while current_time < audio_length:\n",
    "        # Generate a random clip length\n",
    "        clip_length = random.randint(min_clip_length, max_clip_length)\n",
    "\n",
    "        # Add the clip start time to the list\n",
    "        clip_start_times.append(current_time)\n",
    "\n",
    "        # Increment the current time by the clip length\n",
    "        current_time += clip_length\n",
    "\n",
    "    # Generate the output audio clips\n",
    "    for i, start_time in enumerate(clip_start_times):\n",
    "        # Calculate the end time of the clip\n",
    "        end_time = start_time + random.randint(min_clip_length, max_clip_length)\n",
    "\n",
    "        # Ensure that the end time is within the bounds of the audio\n",
    "        if end_time > audio_length:\n",
    "            end_time = audio_length\n",
    "\n",
    "        # Extract the clip from the audio\n",
    "        clip = audio[start_time:end_time]\n",
    "\n",
    "        # Save the clip as a new WAV file\n",
    "        clip_file_path = f'{output_dir}/{os.path.splitext(os.path.basename(wav_file_path))[0]}_clip{i}.wav'\n",
    "        #output_dir +  + '/clip{}.wav'.format(i)\n",
    "        clip.export(clip_file_path, format='wav')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8cb55-62c1-4eed-a0f9-820736c56666",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/home/ubuntu/data/demo/hany_206b_audio'\n",
    "output_dir = '/home/ubuntu/data/demo/hany_206b_clip_audio'\n",
    "\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.wav'):\n",
    "        wav_file_path = os.path.join(input_dir, filename)\n",
    "        split_audio(wav_file_path, output_dir, min_clip_length=7000, max_clip_length=12000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ed4ad-64e4-4779-859a-88b21672ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the demo train/test split data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['type', 'id', 'architecture', 'path', 'label', 'multiclass_label']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "real_path  = '/home/ubuntu/data/demo/hany_206b_clip_audio_16KHz'\n",
    "fake_path = '/home/ubuntu/data/demo/hany_elevenlabs_16KHz'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1e6c9-b851-4c61-8a2a-946f07f17873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-05-10 08:29:34 cloud:56] Found existing object /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo.\n",
      "[NeMo I 2023-05-10 08:29:34 cloud:62] Re-using file from: /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo\n",
      "[NeMo I 2023-05-10 08:29:34 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-05-10 08:29:35 modelPT:156] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 3\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-05-10 08:29:35 modelPT:163] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    time_length: 3\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-05-10 08:29:35 label_models:126] Setting angular: true/false in decoder is deprecated and will be removed in 1.13 version, use specific loss with _target_\n",
      "[NeMo I 2023-05-10 08:29:35 features:267] PADDING: 16\n",
      "[NeMo I 2023-05-10 08:29:35 save_restore_connector:243] Model EncDecSpeakerLabelModel was successfully restored from /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"/home/ubuntu/MultiModalDeepFake\")\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from packages.AudioEmbeddingsManager import generateTitaNetEmbeddings\n",
    "speaker_model = nemo_asr.models.EncDecSpeakerLabelModel.from_pretrained(model_name='titanet_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094a713-2d8c-4f36-981b-74f7a5f13996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(input_dir, output_dir):\n",
    "    \n",
    "    paths = os.listdir(input_dir)\n",
    "    paths = [os.path.join(input_dir, path) for path in paths]\n",
    "    embeddings = generateTitaNetEmbeddings(speaker_model, paths, False)\n",
    "    embeddings_df = pd.DataFrame(embeddings)\n",
    "    embeddings_df['path'] = paths\n",
    "    embeddings_df.to_csv(output_dir, index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637adbf-3b93-41de-9d99-e1af8d03bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_embeddings(fake_path, '/home/ubuntu/data/demo/embeddings/ElevenLabs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becaff50-4c4f-4bf0-ae64-2df81e93b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/MultiModalDeepFake\")\n",
    "from packages.SmileFeatureGenerator import smileFeatureGenerator\n",
    "from datetime import date\n",
    "#base_path\n",
    "base_path = \"/home/ubuntu/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d23939-103d-429a-851b-8260041a0621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/data/demo/hany_elevenlabs_16KHz']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list = []\n",
    "\n",
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "#LJ Speech original all sampling rates\n",
    "path_list.append(base_path + 'data/demo/hany_elevenlabs_16KHz')\n",
    "#path_list.append(base_path + 'data/demo/hany_206b_clip_audio_16KHz')\n",
    "\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f5cdd-411c-4c82-9d18-168c8caa26e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OSF-2023-05-10-demo-hany_elevenlabs_16KHz.csv']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_files = ['-'.join(path.split('/')[4:]) for path in path_list]\n",
    "save_files = ['OSF-' + str(date.today()) + '-' + fn + '.csv' for fn in save_files]\n",
    "save_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e4f5a-98c5-480c-8dc7-ec73c65ac037",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = base_path + 'data/demo/openSmile'\n",
    "save_paths = [save_path + fn for fn in save_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8040a97-e776-4b76-8c1b-bbe93ffbcb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing openSmileOSF-2023-05-10-demo-hany_elevenlabs_16KHz.csv.......\n",
      "\n",
      "Generating openSMILE features...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13073/13073 [41:29<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "openSMILE features generated... call saveFeatures(filename)\n",
      "\n",
      "Features saved to /home/ubuntu/data/demo/openSmileOSF-2023-05-10-demo-hany_elevenlabs_16KHz.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sourcepath, savepath in zip(path_list, save_paths):\n",
    "    \n",
    "    print(\"processing {}.......\\n\".format(savepath.split('/')[-1]))\n",
    "    \n",
    "    try:\n",
    "        featureGenerator = smileFeatureGenerator(sourcepath)\n",
    "    except AssertionError:\n",
    "        print(\"\\nNo wav files found in data path {}\\n\".format(sourcepath))\n",
    "        continue\n",
    "    \n",
    "    featureGenerator.generateFeatures()\n",
    "    featureGenerator.saveFeatures(savepath)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f90e0c8c-ed8c-4a25-b190-768e2eb1a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the data loader path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['type', 'id', 'architecture', 'path', 'label', 'multiclass_label']\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "093d8b1a-7cc9-42eb-b4d2-13690680da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path  = '/home/ubuntu/data/demo/hany_206b_clip_audio_16KHz'\n",
    "fake_path = '/home/ubuntu/data/demo/hany_elevenlabs_16KHz'\n",
    "\n",
    "real_paths = os.listdir(real_path)\n",
    "real_ids = [path.replace('.wav', '') for path in real_paths]\n",
    "real_paths = [os.path.join(real_path, path) for path in real_paths]\n",
    "real_architecture = ['Real']*len(real_paths)\n",
    "real_label = [0]*len(real_paths)\n",
    "real_multiclass_label = [0]*len(real_paths)\n",
    "real_df = pd.DataFrame({'id':real_ids, 'architecture':'Real', 'path':real_paths, 'label':real_label, 'multiclass_label':real_multiclass_label})\n",
    "\n",
    "fake_paths = os.listdir(fake_path)\n",
    "fake_ids = [path.replace('.wav', '') for path in fake_paths]\n",
    "fake_paths = [os.path.join(fake_path, path) for path in fake_paths]\n",
    "fake_architecture = ['Real']*len(fake_paths)\n",
    "fake_label = [1]*len(fake_paths)\n",
    "fake_multiclass_label = [1]*len(fake_paths)\n",
    "fake_df = pd.DataFrame({'id':fake_ids, 'architecture':'ElevenLabs', 'path':fake_paths, 'label':fake_label, 'multiclass_label':fake_multiclass_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "308a8770-470e-4ee0-9d17-a8f90e40ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_real = real_df.sample(frac=1)\n",
    "sample_fake = fake_df.sample(n=sample_real.shape[0])\n",
    "\n",
    "df = pd.concat((sample_real, sample_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfe953e3-a403-4644-9fba-42af34ff93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df['type'] = None\n",
    "df.loc[:int(df.shape[0]*0.8), 'type'] = 'train'\n",
    "df.loc[int(df.shape[0]*0.8):int(df.shape[0]*0.9), 'type'] = 'dev'\n",
    "df.loc[int(df.shape[0]*0.9):, 'type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e18f05c-c305-46af-bb9d-690a8f5aae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/ubuntu/data/demo/demo_train_test_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29085ca7-8ad7-4501-93e2-56c5d4ec1739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "nemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
