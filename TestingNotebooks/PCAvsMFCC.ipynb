{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN0aRbv9jyLjSvpv3PbXetc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#### Articles Used to Generate Code\n",
        "#https://towardsdatascience.com/eigenfaces-recovering-humans-from-ghosts-17606c328184\n",
        "#https://machinelearningmastery.com/face-recognition-using-principal-component-analysis/"
      ],
      "metadata": {
        "id": "3j3SyY5-IQbj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w4DkQeT_CXF",
        "outputId": "cd86a26c-1bb6-426d-e794-abb8edd665d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xJclkam8_Ig3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYM_PATH = '/content/drive/MyDrive/DeepFakeDetection'\n",
        "%cd $SYM_PATH\n",
        "%pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uuj3qbKy_Mc2",
        "outputId": "7ff616fb-861d-47d0-c457-71a2078e8550"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepFakeDetection\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/MyDrive/DeepFakeDetection\n",
            "Installing collected packages: DeepFake\n",
            "  Running setup.py develop for DeepFake\n",
            "Successfully installed DeepFake-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from packages.DlibManager import DlibManager\n",
        "\n",
        "predictor_path = '/content/drive/MyDrive/DeepFakeDetection/model/shape_predictor_68_face_landmarks.dat'\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(predictor_path)"
      ],
      "metadata": {
        "id": "ba6bhGL4_PFr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the metadata\n",
        "metadata = pd.read_csv('/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/meta_data.csv')\n",
        "metadata = metadata[(metadata['method']=='real') | (metadata['method']=='wav2lip')]\n",
        "metadata = metadata.rename(columns={'Unnamed: 9':'full_path'})\n",
        "metadata['full_path'] = metadata['full_path'].str.replace('FakeAVCeleb/', '/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/')\n",
        "metadata['full_path'] = metadata['full_path'] + '/' + metadata['path']"
      ],
      "metadata": {
        "id": "6KlunNuwBP_5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pCAPxMjzDrKb",
        "outputId": "0667c6c1-2239-4c55-9a9e-0eec3c1284e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    source target1 target2 method category                 type     race  \\\n",
              "0  id00076       -       -   real        A  RealVideo-RealAudio  African   \n",
              "1  id00166       -       -   real        A  RealVideo-RealAudio  African   \n",
              "2  id00173       -       -   real        A  RealVideo-RealAudio  African   \n",
              "3  id00366       -       -   real        A  RealVideo-RealAudio  African   \n",
              "4  id00391       -       -   real        A  RealVideo-RealAudio  African   \n",
              "\n",
              "  gender       path                                          full_path  \n",
              "0    men  00109.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "1    men  00010.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "2    men  00118.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "3    men  00118.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "4    men  00052.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8407868-0bc1-45e4-bb05-56cbb7484cf2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>method</th>\n",
              "      <th>category</th>\n",
              "      <th>type</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>path</th>\n",
              "      <th>full_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id00076</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00109.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id00166</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00010.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00173</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00118.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id00366</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00118.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id00391</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00052.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8407868-0bc1-45e4-bb05-56cbb7484cf2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8407868-0bc1-45e4-bb05-56cbb7484cf2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8407868-0bc1-45e4-bb05-56cbb7484cf2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_ids = np.random.choice(metadata.source.unique(), 400, replace=False)\n",
        "testing_ids = np.array(metadata[~metadata['source'].isin(training_ids)]['source'].unique())"
      ],
      "metadata": {
        "id": "9PBia28oBoFv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_videos_details = []\n",
        "failed_training_videos_dlib = []\n",
        "for idx, training_id in enumerate(training_ids):\n",
        "  print(f'Video #{idx+1} out of {len(training_ids)}')\n",
        "\n",
        "  video_path = metadata[(metadata['source'] == training_id) & (metadata['method'] == 'real')]['full_path'].values[0]\n",
        "  video = cv2.VideoCapture(video_path)\n",
        "  audio_path = metadata[(metadata['source'] == training_id) & (metadata['method'] == 'real')]['full_path'].values[0].replace('.mp4', '.wav')\n",
        "  audio, sample_rate = librosa.load(audio_path)\n",
        "\n",
        "  try:\n",
        "    dlib_video = DlibManager(predictor, detector, video)\n",
        "    training_videos_details.append((training_id, dlib_video.lip_frames, audio, sample_rate))\n",
        "\n",
        "  except:\n",
        "    print(f'Failed to Upload: {training_id}')\n",
        "    failed_training_videos_dlib\n",
        "\n",
        "  video.release()\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4WpsJqnNntq",
        "outputId": "4b3a2f0c-61cb-44c2-adbc-5a519515a38e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video #1 out of 400\n",
            "Video #2 out of 400\n",
            "Video #3 out of 400\n",
            "Video #4 out of 400\n",
            "Video #5 out of 400\n",
            "Video #6 out of 400\n",
            "Video #7 out of 400\n",
            "Video #8 out of 400\n",
            "Video #9 out of 400\n",
            "Failed to Upload: id01178\n",
            "Video #10 out of 400\n",
            "Video #11 out of 400\n",
            "Video #12 out of 400\n",
            "Video #13 out of 400\n",
            "Video #14 out of 400\n",
            "Failed to Upload: id07039\n",
            "Video #15 out of 400\n",
            "Video #16 out of 400\n",
            "Video #17 out of 400\n",
            "Video #18 out of 400\n",
            "Video #19 out of 400\n",
            "Video #20 out of 400\n",
            "Failed to Upload: id00021\n",
            "Video #21 out of 400\n",
            "Video #22 out of 400\n",
            "Video #23 out of 400\n",
            "Video #24 out of 400\n",
            "Video #25 out of 400\n",
            "Video #26 out of 400\n",
            "Video #27 out of 400\n",
            "Video #28 out of 400\n",
            "Video #29 out of 400\n",
            "Video #30 out of 400\n",
            "Video #31 out of 400\n",
            "Failed to Upload: id04564\n",
            "Video #32 out of 400\n",
            "Video #33 out of 400\n",
            "Video #34 out of 400\n",
            "Failed to Upload: id06428\n",
            "Video #35 out of 400\n",
            "Video #36 out of 400\n",
            "Video #37 out of 400\n",
            "Failed to Upload: id01392\n",
            "Video #38 out of 400\n",
            "Video #39 out of 400\n",
            "Video #40 out of 400\n",
            "Video #41 out of 400\n",
            "Video #42 out of 400\n",
            "Video #43 out of 400\n",
            "Video #44 out of 400\n",
            "Video #45 out of 400\n",
            "Failed to Upload: id05434\n",
            "Video #46 out of 400\n",
            "Video #47 out of 400\n",
            "Failed to Upload: id01528\n",
            "Video #48 out of 400\n",
            "Video #49 out of 400\n",
            "Video #50 out of 400\n",
            "Video #51 out of 400\n",
            "Video #52 out of 400\n",
            "Video #53 out of 400\n",
            "Video #54 out of 400\n",
            "Video #55 out of 400\n",
            "Video #56 out of 400\n",
            "Failed to Upload: id01717\n",
            "Video #57 out of 400\n",
            "Video #58 out of 400\n",
            "Video #59 out of 400\n",
            "Video #60 out of 400\n",
            "Video #61 out of 400\n",
            "Video #62 out of 400\n",
            "Video #63 out of 400\n",
            "Video #64 out of 400\n",
            "Video #65 out of 400\n",
            "Video #66 out of 400\n",
            "Failed to Upload: id04222\n",
            "Video #67 out of 400\n",
            "Failed to Upload: id00777\n",
            "Video #68 out of 400\n",
            "Video #69 out of 400\n",
            "Video #70 out of 400\n",
            "Video #71 out of 400\n",
            "Video #72 out of 400\n",
            "Video #73 out of 400\n",
            "Video #74 out of 400\n",
            "Video #75 out of 400\n",
            "Video #76 out of 400\n",
            "Video #77 out of 400\n",
            "Video #78 out of 400\n",
            "Failed to Upload: id02567\n",
            "Video #79 out of 400\n",
            "Video #80 out of 400\n",
            "Video #81 out of 400\n",
            "Video #82 out of 400\n",
            "Failed to Upload: id05920\n",
            "Video #83 out of 400\n",
            "Video #84 out of 400\n",
            "Video #85 out of 400\n",
            "Video #86 out of 400\n",
            "Video #87 out of 400\n",
            "Video #88 out of 400\n",
            "Video #89 out of 400\n",
            "Video #90 out of 400\n",
            "Video #91 out of 400\n",
            "Video #92 out of 400\n",
            "Video #93 out of 400\n",
            "Video #94 out of 400\n",
            "Video #95 out of 400\n",
            "Video #96 out of 400\n",
            "Video #97 out of 400\n",
            "Video #98 out of 400\n",
            "Video #99 out of 400\n",
            "Video #100 out of 400\n",
            "Failed to Upload: id06427\n",
            "Video #101 out of 400\n",
            "Video #102 out of 400\n",
            "Video #103 out of 400\n",
            "Failed to Upload: id01281\n",
            "Video #104 out of 400\n",
            "Failed to Upload: id02342\n",
            "Video #105 out of 400\n",
            "Video #106 out of 400\n",
            "Video #107 out of 400\n",
            "Failed to Upload: id04705\n",
            "Video #108 out of 400\n",
            "Failed to Upload: id01036\n",
            "Video #109 out of 400\n",
            "Video #110 out of 400\n",
            "Video #111 out of 400\n",
            "Video #112 out of 400\n",
            "Video #113 out of 400\n",
            "Video #114 out of 400\n",
            "Video #115 out of 400\n",
            "Video #116 out of 400\n",
            "Video #117 out of 400\n",
            "Failed to Upload: id02948\n",
            "Video #118 out of 400\n",
            "Failed to Upload: id06354\n",
            "Video #119 out of 400\n",
            "Failed to Upload: id02808\n",
            "Video #120 out of 400\n",
            "Video #121 out of 400\n",
            "Video #122 out of 400\n",
            "Video #123 out of 400\n",
            "Failed to Upload: id00761\n",
            "Video #124 out of 400\n",
            "Failed to Upload: id06158\n",
            "Video #125 out of 400\n",
            "Video #126 out of 400\n",
            "Video #127 out of 400\n",
            "Video #128 out of 400\n",
            "Video #129 out of 400\n",
            "Video #130 out of 400\n",
            "Video #131 out of 400\n",
            "Video #132 out of 400\n",
            "Video #133 out of 400\n",
            "Video #134 out of 400\n",
            "Video #135 out of 400\n",
            "Video #136 out of 400\n",
            "Video #137 out of 400\n",
            "Video #138 out of 400\n",
            "Video #139 out of 400\n",
            "Video #140 out of 400\n",
            "Video #141 out of 400\n",
            "Video #142 out of 400\n",
            "Video #143 out of 400\n",
            "Video #144 out of 400\n",
            "Video #145 out of 400\n",
            "Video #146 out of 400\n",
            "Video #147 out of 400\n",
            "Video #148 out of 400\n",
            "Video #149 out of 400\n",
            "Failed to Upload: id08313\n",
            "Video #150 out of 400\n",
            "Video #151 out of 400\n",
            "Video #152 out of 400\n",
            "Video #153 out of 400\n",
            "Video #154 out of 400\n",
            "Video #155 out of 400\n",
            "Video #156 out of 400\n",
            "Video #157 out of 400\n",
            "Failed to Upload: id02040\n",
            "Video #158 out of 400\n",
            "Video #159 out of 400\n",
            "Video #160 out of 400\n",
            "Video #161 out of 400\n",
            "Video #162 out of 400\n",
            "Failed to Upload: id01532\n",
            "Video #163 out of 400\n",
            "Video #164 out of 400\n",
            "Video #165 out of 400\n",
            "Video #166 out of 400\n",
            "Video #167 out of 400\n",
            "Failed to Upload: id01783\n",
            "Video #168 out of 400\n",
            "Video #169 out of 400\n",
            "Video #170 out of 400\n",
            "Video #171 out of 400\n",
            "Failed to Upload: id06591\n",
            "Video #172 out of 400\n",
            "Video #173 out of 400\n",
            "Video #174 out of 400\n",
            "Video #175 out of 400\n",
            "Video #176 out of 400\n",
            "Video #177 out of 400\n",
            "Video #178 out of 400\n",
            "Video #179 out of 400\n",
            "Video #180 out of 400\n",
            "Video #181 out of 400\n",
            "Video #182 out of 400\n",
            "Video #183 out of 400\n",
            "Video #184 out of 400\n",
            "Failed to Upload: id04691\n",
            "Video #185 out of 400\n",
            "Failed to Upload: id04547\n",
            "Video #186 out of 400\n",
            "Video #187 out of 400\n",
            "Video #188 out of 400\n",
            "Failed to Upload: id06225\n",
            "Video #189 out of 400\n",
            "Failed to Upload: id00137\n",
            "Video #190 out of 400\n",
            "Video #191 out of 400\n",
            "Failed to Upload: id04939\n",
            "Video #192 out of 400\n",
            "Video #193 out of 400\n",
            "Video #194 out of 400\n",
            "Video #195 out of 400\n",
            "Video #196 out of 400\n",
            "Video #197 out of 400\n",
            "Video #198 out of 400\n",
            "Video #199 out of 400\n",
            "Video #200 out of 400\n",
            "Video #201 out of 400\n",
            "Video #202 out of 400\n",
            "Video #203 out of 400\n",
            "Video #204 out of 400\n",
            "Video #205 out of 400\n",
            "Video #206 out of 400\n",
            "Video #207 out of 400\n",
            "Failed to Upload: id01170\n",
            "Video #208 out of 400\n",
            "Video #209 out of 400\n",
            "Video #210 out of 400\n",
            "Failed to Upload: id04599\n",
            "Video #211 out of 400\n",
            "Video #212 out of 400\n",
            "Video #213 out of 400\n",
            "Video #214 out of 400\n",
            "Video #215 out of 400\n",
            "Video #216 out of 400\n",
            "Video #217 out of 400\n",
            "Video #218 out of 400\n",
            "Video #219 out of 400\n",
            "Video #220 out of 400\n",
            "Video #221 out of 400\n",
            "Video #222 out of 400\n",
            "Video #223 out of 400\n",
            "Video #224 out of 400\n",
            "Failed to Upload: id01995\n",
            "Video #225 out of 400\n",
            "Failed to Upload: id01661\n",
            "Video #226 out of 400\n",
            "Video #227 out of 400\n",
            "Failed to Upload: id03945\n",
            "Video #228 out of 400\n",
            "Video #229 out of 400\n",
            "Video #230 out of 400\n",
            "Video #231 out of 400\n",
            "Failed to Upload: id03205\n",
            "Video #232 out of 400\n",
            "Video #233 out of 400\n",
            "Video #234 out of 400\n",
            "Video #235 out of 400\n",
            "Video #236 out of 400\n",
            "Video #237 out of 400\n",
            "Video #238 out of 400\n",
            "Video #239 out of 400\n",
            "Video #240 out of 400\n",
            "Video #241 out of 400\n",
            "Video #242 out of 400\n",
            "Video #243 out of 400\n",
            "Failed to Upload: id01210\n",
            "Video #244 out of 400\n",
            "Video #245 out of 400\n",
            "Video #246 out of 400\n",
            "Video #247 out of 400\n",
            "Failed to Upload: id01933\n",
            "Video #248 out of 400\n",
            "Video #249 out of 400\n",
            "Video #250 out of 400\n",
            "Video #251 out of 400\n",
            "Video #252 out of 400\n",
            "Video #253 out of 400\n",
            "Video #254 out of 400\n",
            "Failed to Upload: id07463\n",
            "Video #255 out of 400\n",
            "Video #256 out of 400\n",
            "Video #257 out of 400\n",
            "Video #258 out of 400\n",
            "Video #259 out of 400\n",
            "Failed to Upload: id00403\n",
            "Video #260 out of 400\n",
            "Video #261 out of 400\n",
            "Video #262 out of 400\n",
            "Video #263 out of 400\n",
            "Video #264 out of 400\n",
            "Video #265 out of 400\n",
            "Video #266 out of 400\n",
            "Video #267 out of 400\n",
            "Video #268 out of 400\n",
            "Failed to Upload: id05844\n",
            "Video #269 out of 400\n",
            "Video #270 out of 400\n",
            "Video #271 out of 400\n",
            "Video #272 out of 400\n",
            "Video #273 out of 400\n",
            "Video #274 out of 400\n",
            "Video #275 out of 400\n",
            "Video #276 out of 400\n",
            "Video #277 out of 400\n",
            "Video #278 out of 400\n",
            "Failed to Upload: id02071\n",
            "Video #279 out of 400\n",
            "Video #280 out of 400\n",
            "Video #281 out of 400\n",
            "Failed to Upload: id03858\n",
            "Video #282 out of 400\n",
            "Video #283 out of 400\n",
            "Video #284 out of 400\n",
            "Video #285 out of 400\n",
            "Failed to Upload: id04789\n",
            "Video #286 out of 400\n",
            "Video #287 out of 400\n",
            "Failed to Upload: id01005\n",
            "Video #288 out of 400\n",
            "Video #289 out of 400\n",
            "Video #290 out of 400\n",
            "Video #291 out of 400\n",
            "Video #292 out of 400\n",
            "Video #293 out of 400\n",
            "Video #294 out of 400\n",
            "Video #295 out of 400\n",
            "Video #296 out of 400\n",
            "Video #297 out of 400\n",
            "Video #298 out of 400\n",
            "Failed to Upload: id00633\n",
            "Video #299 out of 400\n",
            "Video #300 out of 400\n",
            "Video #301 out of 400\n",
            "Video #302 out of 400\n",
            "Video #303 out of 400\n",
            "Video #304 out of 400\n",
            "Video #305 out of 400\n",
            "Video #306 out of 400\n",
            "Video #307 out of 400\n",
            "Video #308 out of 400\n",
            "Video #309 out of 400\n",
            "Video #310 out of 400\n",
            "Video #311 out of 400\n",
            "Video #312 out of 400\n",
            "Video #313 out of 400\n",
            "Video #314 out of 400\n",
            "Video #315 out of 400\n",
            "Video #316 out of 400\n",
            "Video #317 out of 400\n",
            "Video #318 out of 400\n",
            "Video #319 out of 400\n",
            "Video #320 out of 400\n",
            "Failed to Upload: id03658\n",
            "Video #321 out of 400\n",
            "Failed to Upload: id03696\n",
            "Video #322 out of 400\n",
            "Video #323 out of 400\n",
            "Video #324 out of 400\n",
            "Video #325 out of 400\n",
            "Failed to Upload: id07058\n",
            "Video #326 out of 400\n",
            "Failed to Upload: id02617\n",
            "Video #327 out of 400\n",
            "Failed to Upload: id04582\n",
            "Video #328 out of 400\n",
            "Video #329 out of 400\n",
            "Failed to Upload: id01215\n",
            "Video #330 out of 400\n",
            "Video #331 out of 400\n",
            "Failed to Upload: id03941\n",
            "Video #332 out of 400\n",
            "Video #333 out of 400\n",
            "Failed to Upload: id04928\n",
            "Video #334 out of 400\n",
            "Video #335 out of 400\n",
            "Video #336 out of 400\n",
            "Video #337 out of 400\n",
            "Video #338 out of 400\n",
            "Video #339 out of 400\n",
            "Video #340 out of 400\n",
            "Video #341 out of 400\n",
            "Video #342 out of 400\n",
            "Video #343 out of 400\n",
            "Video #344 out of 400\n",
            "Failed to Upload: id00185\n",
            "Video #345 out of 400\n",
            "Video #346 out of 400\n",
            "Failed to Upload: id02807\n",
            "Video #347 out of 400\n",
            "Video #348 out of 400\n",
            "Failed to Upload: id00126\n",
            "Video #349 out of 400\n",
            "Video #350 out of 400\n",
            "Video #351 out of 400\n",
            "Video #352 out of 400\n",
            "Video #353 out of 400\n",
            "Video #354 out of 400\n",
            "Video #355 out of 400\n",
            "Video #356 out of 400\n",
            "Video #357 out of 400\n",
            "Video #358 out of 400\n",
            "Video #359 out of 400\n",
            "Video #360 out of 400\n",
            "Failed to Upload: id04073\n",
            "Video #361 out of 400\n",
            "Video #362 out of 400\n",
            "Video #363 out of 400\n",
            "Video #364 out of 400\n",
            "Video #365 out of 400\n",
            "Video #366 out of 400\n",
            "Video #367 out of 400\n",
            "Video #368 out of 400\n",
            "Video #369 out of 400\n",
            "Video #370 out of 400\n",
            "Video #371 out of 400\n",
            "Video #372 out of 400\n",
            "Video #373 out of 400\n",
            "Video #374 out of 400\n",
            "Video #375 out of 400\n",
            "Video #376 out of 400\n",
            "Video #377 out of 400\n",
            "Failed to Upload: id04221\n",
            "Video #378 out of 400\n",
            "Failed to Upload: id00577\n",
            "Video #379 out of 400\n",
            "Video #380 out of 400\n",
            "Video #381 out of 400\n",
            "Video #382 out of 400\n",
            "Video #383 out of 400\n",
            "Video #384 out of 400\n",
            "Video #385 out of 400\n",
            "Failed to Upload: id00183\n",
            "Video #386 out of 400\n",
            "Video #387 out of 400\n",
            "Video #388 out of 400\n",
            "Video #389 out of 400\n",
            "Video #390 out of 400\n",
            "Video #391 out of 400\n",
            "Failed to Upload: id03379\n",
            "Video #392 out of 400\n",
            "Video #393 out of 400\n",
            "Video #394 out of 400\n",
            "Video #395 out of 400\n",
            "Video #396 out of 400\n",
            "Video #397 out of 400\n",
            "Video #398 out of 400\n",
            "Video #399 out of 400\n",
            "Video #400 out of 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#video_path = '/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/RealVideo-RealAudio/African/men/id00076/00109.mp4'\n",
        "#video = cv2.VideoCapture(video_path)\n",
        "\n",
        "#predictor_path = '/content/drive/MyDrive/DeepFakeDetection/model/shape_predictor_68_face_landmarks.dat'\n",
        "#detector = dlib.get_frontal_face_detector()\n",
        "#predictor = dlib.shape_predictor(predictor_path)"
      ],
      "metadata": {
        "id": "FFY6AqKG_0Cw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#audio_path = '/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/RealVideo-RealAudio/African/men/id00076/00109.wav'\n",
        "#audio, sample_rate = librosa.load(audio_path)"
      ],
      "metadata": {
        "id": "3ZqUBJjYSsfP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vid1_dlib = DlibManager(predictor, detector, video)"
      ],
      "metadata": {
        "id": "1yKfJjBb_4Sc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_lips(lip_frames, height=90, width=70):\n",
        "\n",
        "  lip_frames_resized = []\n",
        "\n",
        "  for frame in lip_frames:\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    resized_frame = cv2.resize(frame, (height, width))\n",
        "    lip_frames_resized.append(resized_frame)\n",
        "\n",
        "  lip_frames_resized = np.array(lip_frames_resized)\n",
        "  lip_frames_resized = lip_frames_resized.reshape(lip_frames_resized.shape[0], lip_frames_resized.shape[1]*lip_frames_resized.shape[2])\n",
        "\n",
        "  return lip_frames_resized\n"
      ],
      "metadata": {
        "id": "BRq7sHEApa4q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resize all the lip frames to 70 x 90\n",
        "#lip_frames_resized = []\n",
        "#for frame in vid1_dlib.lip_frames:\n",
        "#  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "#  resized_frame = cv2.resize(frame, (90, 70))\n",
        "#  lip_frames_resized.append(resized_frame)\n",
        "#lip_frames_resized = np.array(lip_frames_resized)"
      ],
      "metadata": {
        "id": "l40iR1mk_95A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(training_video_details, num_components):\n",
        "  \n",
        "  lips_data = None\n",
        "  X  = None\n",
        "  y = None\n",
        "\n",
        "  for idx, training_video_data in enumerate(training_video_details):\n",
        "    if len(training_video_data) > 4:\n",
        "      for item in training_video_data:\n",
        "        print(item)\n",
        "    id, lip_frames, audio, sample_rate = training_video_data\n",
        "\n",
        "    lip_frames_resized = preprocess_lips(lip_frames)\n",
        "    #lip_frames_resized = lip_frames_resized.reshape(lip_frames_resized.shape[0], lip_frames_resized.shape[1]*lip_frames_resized.shape[2])\n",
        "    \n",
        "    row_count = lip_frames_resized.shape[0]\n",
        "\n",
        "    mfcc_features = librosa.feature.mfcc(y=audio, hop_length=int(sample_rate*librosa.get_duration(audio)/row_count)).T[:row_count, :]\n",
        "\n",
        "    if isinstance(lips_data, type(None)):\n",
        "      lips_data = lip_frames_resized\n",
        "      y = mfcc_features\n",
        "    else:\n",
        "      lips_data = np.vstack((lips_data, lip_frames_resized))\n",
        "      y = np.vstack((y, mfcc_features))\n",
        "\n",
        "  \n",
        "  lips_data_mean = np.mean(lips_data, axis=0)\n",
        "  lips_data_centered = lips_data - lips_data_mean\n",
        "\n",
        "  pca = PCA()\n",
        "  pca_lip_frames = pca.fit_transform(lips_data_centered)\n",
        "\n",
        "  eigenfaces = pca.components_[:num_components]\n",
        "  weights = np.dot(lips_data_centered, eigenfaces.T)\n",
        "\n",
        "  X = weights\n",
        "\n",
        "  return X, y, lips_data_mean, pca\n"
      ],
      "metadata": {
        "id": "H7h8MfxSr6gG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, lips_data_mean, pca = generate_training_data(training_videos_details, 10)"
      ],
      "metadata": {
        "id": "-C99Ys5Cy7We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models(X, y):\n",
        "\n",
        "  num_coef = y.shape[1]\n",
        "  models = []\n",
        "  for i in range(num_coef):\n",
        "    model = LinearRegression().fit(X, y[:, i])\n",
        "    models.append(model)\n",
        "\n",
        "  return models"
      ],
      "metadata": {
        "id": "PNikq-HRS4cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = train_models(X, y)"
      ],
      "metadata": {
        "id": "CIzqbjmJTh4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_videos_details = []\n",
        "failed_testing_videos_dlib = []\n",
        "for idx, testing_id in enumerate(testing_ids):\n",
        "  print(f'Video #{idx+1} out of {len(testing_ids)}')\n",
        "\n",
        "  real_video_path = metadata[(metadata['source'] == testing_id) & (metadata['method'] == 'real')]['full_path'].values[0]\n",
        "  fake_video_path = metadata[(metadata['source'] == testing_id) & (metadata['method']=='wav2lip')].sample(1)['full_path'].values[0]\n",
        "\n",
        "  real_video = cv2.VideoCapture(real_video_path)\n",
        "  fake_video = cv2.VideoCapture(fake_video_path)\n",
        "\n",
        "  real_audio_path = real_video_path.replace('.mp4', '.wav')\n",
        "  fake_audio_path = fake_video_path.replace('.mp4', '.wav')\n",
        "\n",
        "  real_audio, real_sample_rate = librosa.load(real_audio_path)\n",
        "  fake_audio, fake_sample_rate = librosa.load(fake_audio_path)\n",
        "\n",
        "  try:\n",
        "    real_dlib_video = DlibManager(predictor, detector, real_video)\n",
        "    fake_dlib_video = DlibManager(predictor, detector, fake_video)\n",
        "    testing_videos_details.append((testing_id, real_dlib_video.lip_frames, fake_dlib_video.lip_frames, real_audio, fake_audio, real_sample_rate, fake_sample_rate))\n",
        "\n",
        "  except:\n",
        "    print(f'Failed to Upload: {testing_id}')\n",
        "    testing_videos_details.append((real_video_path, fake_video_path))\n",
        "\n",
        "  real_video.release()\n",
        "  fake_video.release()"
      ],
      "metadata": {
        "id": "mchZU50aNqpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_test_data(testing_video_details, pca, lips_data_mean, models, num_components=10, debug_mode=False):\n",
        "\n",
        "  real_video_error = []\n",
        "  fake_video_error = []\n",
        "\n",
        "  for idx, testing_video in enumerate(testing_video_details):\n",
        "\n",
        "    real_mfcc_errors = []\n",
        "    fake_mfcc_errors = []\n",
        "\n",
        "    testing_id, real_lip_frames, fake_lip_frames, real_audio, fake_audio, real_sample_rate, fake_sample_rate = testing_video\n",
        "\n",
        "    real_lip_frames_resized = preprocess_lips(real_lip_frames)\n",
        "    fake_lip_frames_resized = preprocess_lips(fake_lip_frames)\n",
        "\n",
        "    if debug_mode:\n",
        "      print('LIP FRAME SHAPES')\n",
        "      print('Real Lip Frames: ', real_lip_frames_resized.shape)\n",
        "      print('Fake Lip Frames: ', fake_lip_frames_resized.shape)\n",
        "      print('--------------------------------------------')\n",
        "\n",
        "    real_row_count = real_lip_frames_resized.shape[0]\n",
        "    fake_row_count = fake_lip_frames_resized.shape[0]\n",
        "\n",
        "    real_mfcc_features = librosa.feature.mfcc(y=audio, hop_length=int(real_sample_rate*librosa.get_duration(real_audio)/real_row_count)).T[:real_row_count, :]\n",
        "    fake_mfcc_features = librosa.feature.mfcc(y=audio, hop_length=int(fake_sample_rate*librosa.get_duration(fake_audio)/fake_row_count)).T[:fake_row_count, :]\n",
        "\n",
        "    if debug_mode:\n",
        "      print('ORIGINAL MFCC FRAME SHAPES')\n",
        "      print('Real MFCC Frames: ', librosa.feature.mfcc(y=audio, hop_length=int(real_sample_rate*librosa.get_duration(real_audio)/real_row_count)).T.shape)\n",
        "      print('Fake MFCC Frames: ', librosa.feature.mfcc(y=audio, hop_length=int(fake_sample_rate*librosa.get_duration(fake_audio)/fake_row_count)).T.shape)\n",
        "      print('--------------------------------------------')\n",
        "\n",
        "\n",
        "    real_lips_centered = real_lip_frames_resized - lips_data_mean\n",
        "    fake_lips_centered = fake_lip_frames_resized - lips_data_mean\n",
        "\n",
        "    real_pca_lip_frames = pca.transform(real_lips_centered)\n",
        "    fake_pca_lip_frames = pca.transform(fake_lips_centered)\n",
        "\n",
        "\n",
        "    eigenfaces = pca.components_[:num_components]\n",
        "    real_weights = np.dot(real_lips_centered, eigenfaces.T)\n",
        "    fake_weights = np.dot(fake_lips_centered, eigenfaces.T)\n",
        "\n",
        "    X_real = real_weights\n",
        "    X_fake = fake_weights\n",
        "    y_real = real_mfcc_features\n",
        "    y_fake = fake_mfcc_features\n",
        "\n",
        "\n",
        "    if debug_mode:\n",
        "      print('TRAINING DATA SHAPES')\n",
        "      print('X Real Shape:', X_real.shape)\n",
        "      print('X Fake Shape:', X_fake.shape)\n",
        "      print('y Real Shape:', y_real.shape)\n",
        "      print('y Fake Shape:', y_fake.shape)\n",
        "      print('--------------------------------------------')\n",
        "\n",
        "    for idx, model in enumerate(models):\n",
        "      y_real_pred = model.predict(X_real)\n",
        "      y_fake_pred = model.predict(X_fake)\n",
        "\n",
        "      real_err = np.sqrt(mean_squared_error(y_true=y_real[:, idx], y_pred=y_real_pred))/len(y_real_pred)\n",
        "      fake_err = np.sqrt(mean_squared_error(y_true=y_fake[:, idx], y_pred=y_fake_pred))/len(y_fake_pred)\n",
        "\n",
        "      real_mfcc_errors.append(real_err)\n",
        "      fake_mfcc_errors.append(fake_err)\n",
        "\n",
        "    real_video_error.append(np.mean(real_mfcc_errors))\n",
        "    fake_video_error.append(np.mean(fake_mfcc_errors))\n",
        "\n",
        "\n",
        "    return real_video_error, fake_video_error\n"
      ],
      "metadata": {
        "id": "n1TJqSOszk3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_video_error, fake_video_error = eval_test_data(testing_videos_details, pca, lips_data_mean, models, 10, True)"
      ],
      "metadata": {
        "id": "2n4T6N3taoSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape_lip_frames = lip_frames_resized.reshape(lip_frames_resized.shape[0], lip_frames_resized.shape[1]*lip_frames_resized.shape[2])\n"
      ],
      "metadata": {
        "id": "7MjQDhGzASQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar = StandardScaler()\n",
        "#centered_lip_frames = scalar.fit_transform(reshape_lip_frames)\n",
        "\n",
        "#avg_lip_frames = np.mean(reshape_lip_frames, axis=0)\n",
        "#centered_lip_frames = reshape_lip_frames - avg_lip_frames"
      ],
      "metadata": {
        "id": "h1aCxyvKCqcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pca = PCA()\n",
        "#pca_lip_frames = pca.fit_transform(centered_lip_frames)"
      ],
      "metadata": {
        "id": "eHL-cc9IC0NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random_samples = np.random.choice(np.arange(0, reshape_lip_frames.shape[0]), 5)\n",
        "#random_samples"
      ],
      "metadata": {
        "id": "UFZC6xFpE-zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruction(pca, num_components, centered_data, mean, image_idx, height=70, width=90):\n",
        "  eigenfaces = pca.components_[:num_components]\n",
        "  samples, features = centered_data.shape\n",
        "  weights = np.dot(centered_data, eigenfaces.T)\n",
        "  recovered_image = (np.dot(weights[image_idx,:], eigenfaces)+mean).reshape(height, width)\n",
        "  return recovered_image\n",
        "\n"
      ],
      "metadata": {
        "id": "cKGxEvy-HP37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(5,2,sharex=True,sharey=True,figsize=(8,10))\n",
        "fig.suptitle('Eigenface Count: 1', fontsize=16)\n",
        "for idx, sample in enumerate(random_samples):\n",
        "  orig = vid1_dlib.lip_frames[sample]\n",
        "  reconstructed = reconstruction(pca, 1, centered_lip_frames, avg_lip_frames, sample)\n",
        "  axes[idx, 0].imshow(orig)\n",
        "  axes[idx, 1].imshow(reconstructed, cmap=\"gray\")\n",
        "plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "FBhOBoYTHAX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(5,2,sharex=True,sharey=True,figsize=(8,10))\n",
        "fig.suptitle('Eigenface Count: 10', fontsize=16)\n",
        "for idx, sample in enumerate(random_samples):\n",
        "  orig = vid1_dlib.lip_frames[sample]\n",
        "  reconstructed = reconstruction(pca, 10, centered_lip_frames, avg_lip_frames, sample)\n",
        "  axes[idx, 0].imshow(orig)\n",
        "  axes[idx, 1].imshow(reconstructed, cmap=\"gray\")\n",
        "plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "NDX69bvtM7VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_features = librosa.feature.mfcc(y=audio, hop_length=int(sample_rate*librosa.get_duration(audio)/251)).T[:251, :]"
      ],
      "metadata": {
        "id": "pUt8FycOOgQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_one_mfcc = mfcc_features[:, 0].reshape(251, 1)"
      ],
      "metadata": {
        "id": "Ka-PktduTNCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights.shape"
      ],
      "metadata": {
        "id": "ePIDL0n9X2SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_one_mfcc.shape\n"
      ],
      "metadata": {
        "id": "de0zdR8VX4K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigenfaces = pca.components_[:10]\n",
        "samples, features = centered_lip_frames.shape\n",
        "weights = np.dot(centered_lip_frames, eigenfaces.T)\n",
        "\n",
        "train_test_data = np.hstack((weights, coef_one_mfcc.reshape(251, 1)))"
      ],
      "metadata": {
        "id": "N86oeeA8Ujgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(weights, coef_one_mfcc, test_size=0.15, random_state=12)"
      ],
      "metadata": {
        "id": "ypEk_8StWCLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "err = np.sqrt(mean_squared_error(y_true=y_test, y_pred=pred))/len(pred)\n",
        "print(err)"
      ],
      "metadata": {
        "id": "UbhXQwy4WUPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y)"
      ],
      "metadata": {
        "id": "iWffI7VThrRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(X_test, y_):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=12)\n",
        "\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  pred = model.predict(X_test)\n",
        "  err = np.sqrt(mean_squared_error(y_true=y_test, y_pred=pred))/len(pred)\n",
        "\n",
        "  return pred, err\n",
        "\n"
      ],
      "metadata": {
        "id": "elmNUPsIgH81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef_one_mfcc"
      ],
      "metadata": {
        "id": "paM7O2PLaZ2R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}