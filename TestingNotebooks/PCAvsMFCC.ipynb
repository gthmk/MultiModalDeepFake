{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMM4Qt8ucSnOemuo4ofdy7T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romitbarua/MultiModalDeepFake/blob/main/TestingNotebooks/PCAvsMFCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Articles Used to Generate Code\n",
        "#https://towardsdatascience.com/eigenfaces-recovering-humans-from-ghosts-17606c328184\n",
        "#https://machinelearningmastery.com/face-recognition-using-principal-component-analysis/"
      ],
      "metadata": {
        "id": "3j3SyY5-IQbj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w4DkQeT_CXF",
        "outputId": "37693299-af7a-44d1-ac99-91c8d3189d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "xJclkam8_Ig3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYM_PATH = '/content/drive/MyDrive/DeepFakeDetection'\n",
        "%cd $SYM_PATH\n",
        "%pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uuj3qbKy_Mc2",
        "outputId": "de05fa11-1ab3-4979-89f2-73b8e7c293f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepFakeDetection\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/MyDrive/DeepFakeDetection\n",
            "Installing collected packages: DeepFake\n",
            "  Running setup.py develop for DeepFake\n",
            "Successfully installed DeepFake-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from packages.DlibManager import DlibManager\n",
        "\n",
        "predictor_path = '/content/drive/MyDrive/DeepFakeDetection/model/shape_predictor_68_face_landmarks.dat'\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(predictor_path)"
      ],
      "metadata": {
        "id": "ba6bhGL4_PFr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the metadata\n",
        "metadata = pd.read_csv('/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/meta_data.csv')\n",
        "metadata = metadata[(metadata['method']=='real') | (metadata['method']=='wav2lip')]\n",
        "metadata = metadata.rename(columns={'Unnamed: 9':'full_path'})\n",
        "metadata['full_path'] = metadata['full_path'].str.replace('FakeAVCeleb/', '/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/')\n",
        "metadata['full_path'] = metadata['full_path'] + '/' + metadata['path']\n",
        "metadata = metadata[metadata['gender']=='men']"
      ],
      "metadata": {
        "id": "6KlunNuwBP_5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pCAPxMjzDrKb",
        "outputId": "ad45c1fc-2f1e-4a9e-8aab-fcf443a038bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    source target1 target2 method category                 type     race  \\\n",
              "0  id00076       -       -   real        A  RealVideo-RealAudio  African   \n",
              "1  id00166       -       -   real        A  RealVideo-RealAudio  African   \n",
              "2  id00173       -       -   real        A  RealVideo-RealAudio  African   \n",
              "3  id00366       -       -   real        A  RealVideo-RealAudio  African   \n",
              "4  id00391       -       -   real        A  RealVideo-RealAudio  African   \n",
              "\n",
              "  gender       path                                          full_path  \n",
              "0    men  00109.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "1    men  00010.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "2    men  00118.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "3    men  00118.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  \n",
              "4    men  00052.mp4  /content/drive/MyDrive/DeepFakeDetection/data/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b74ea086-c5f2-4441-a570-6c7e1aae2cc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>method</th>\n",
              "      <th>category</th>\n",
              "      <th>type</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>path</th>\n",
              "      <th>full_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id00076</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00109.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id00166</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00010.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00173</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00118.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id00366</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00118.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id00391</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>real</td>\n",
              "      <td>A</td>\n",
              "      <td>RealVideo-RealAudio</td>\n",
              "      <td>African</td>\n",
              "      <td>men</td>\n",
              "      <td>00052.mp4</td>\n",
              "      <td>/content/drive/MyDrive/DeepFakeDetection/data/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b74ea086-c5f2-4441-a570-6c7e1aae2cc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b74ea086-c5f2-4441-a570-6c7e1aae2cc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b74ea086-c5f2-4441-a570-6c7e1aae2cc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_ids = np.random.choice(metadata.source.unique(), int(metadata.source.unique().shape[0]*0.8), replace=False)\n",
        "testing_ids = np.array(metadata[~metadata['source'].isin(training_ids)]['source'].unique())"
      ],
      "metadata": {
        "id": "9PBia28oBoFv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_videos_details = []\n",
        "failed_training_videos_dlib = []\n",
        "for idx, training_id in enumerate(training_ids):\n",
        "  print(f'Video #{idx+1} out of {len(training_ids)}')\n",
        "\n",
        "  video_path = metadata[(metadata['source'] == training_id) & (metadata['method'] == 'real')]['full_path'].values[0]\n",
        "  video = cv2.VideoCapture(video_path)\n",
        "  audio_path = metadata[(metadata['source'] == training_id) & (metadata['method'] == 'real')]['full_path'].values[0].replace('.mp4', '.wav')\n",
        "  audio, sample_rate = librosa.load(audio_path)\n",
        "\n",
        "  try:\n",
        "    dlib_video = DlibManager(predictor, detector, video)\n",
        "    training_videos_details.append((training_id, dlib_video.lip_frames, audio, sample_rate))\n",
        "\n",
        "  except:\n",
        "    print(f'Failed to Upload: {training_id}')\n",
        "    failed_training_videos_dlib\n",
        "\n",
        "  video.release()\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4WpsJqnNntq",
        "outputId": "b3d8b1c2-0dc2-436f-d72f-c0d898fa9b38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video #1 out of 200\n",
            "Video #2 out of 200\n",
            "Video #3 out of 200\n",
            "Video #4 out of 200\n",
            "Video #5 out of 200\n",
            "Video #6 out of 200\n",
            "Video #7 out of 200\n",
            "Video #8 out of 200\n",
            "Video #9 out of 200\n",
            "Video #10 out of 200\n",
            "Video #11 out of 200\n",
            "Video #12 out of 200\n",
            "Failed to Upload: id01528\n",
            "Video #13 out of 200\n",
            "Video #14 out of 200\n",
            "Video #15 out of 200\n",
            "Video #16 out of 200\n",
            "Video #17 out of 200\n",
            "Video #18 out of 200\n",
            "Video #19 out of 200\n",
            "Video #20 out of 200\n",
            "Video #21 out of 200\n",
            "Failed to Upload: id00777\n",
            "Video #22 out of 200\n",
            "Video #23 out of 200\n",
            "Video #24 out of 200\n",
            "Video #25 out of 200\n",
            "Failed to Upload: id04221\n",
            "Video #26 out of 200\n",
            "Video #27 out of 200\n",
            "Video #28 out of 200\n",
            "Video #29 out of 200\n",
            "Video #30 out of 200\n",
            "Video #31 out of 200\n",
            "Video #32 out of 200\n",
            "Video #33 out of 200\n",
            "Failed to Upload: id04789\n",
            "Video #34 out of 200\n",
            "Video #35 out of 200\n",
            "Video #36 out of 200\n",
            "Video #37 out of 200\n",
            "Video #38 out of 200\n",
            "Video #39 out of 200\n",
            "Video #40 out of 200\n",
            "Video #41 out of 200\n",
            "Video #42 out of 200\n",
            "Video #43 out of 200\n",
            "Video #44 out of 200\n",
            "Video #45 out of 200\n",
            "Failed to Upload: id08313\n",
            "Video #46 out of 200\n",
            "Video #47 out of 200\n",
            "Video #48 out of 200\n",
            "Video #49 out of 200\n",
            "Video #50 out of 200\n",
            "Video #51 out of 200\n",
            "Video #52 out of 200\n",
            "Video #53 out of 200\n",
            "Video #54 out of 200\n",
            "Failed to Upload: id01170\n",
            "Video #55 out of 200\n",
            "Video #56 out of 200\n",
            "Video #57 out of 200\n",
            "Failed to Upload: id02567\n",
            "Video #58 out of 200\n",
            "Video #59 out of 200\n",
            "Video #60 out of 200\n",
            "Video #61 out of 200\n",
            "Failed to Upload: id04073\n",
            "Video #62 out of 200\n",
            "Video #63 out of 200\n",
            "Video #64 out of 200\n",
            "Video #65 out of 200\n",
            "Video #66 out of 200\n",
            "Video #67 out of 200\n",
            "Video #68 out of 200\n",
            "Video #69 out of 200\n",
            "Failed to Upload: id04599\n",
            "Video #70 out of 200\n",
            "Video #71 out of 200\n",
            "Video #72 out of 200\n",
            "Video #73 out of 200\n",
            "Failed to Upload: id04691\n",
            "Video #74 out of 200\n",
            "Video #75 out of 200\n",
            "Video #76 out of 200\n",
            "Video #77 out of 200\n",
            "Video #78 out of 200\n",
            "Video #79 out of 200\n",
            "Video #80 out of 200\n",
            "Video #81 out of 200\n",
            "Failed to Upload: id00185\n",
            "Video #82 out of 200\n",
            "Video #83 out of 200\n",
            "Video #84 out of 200\n",
            "Failed to Upload: id00366\n",
            "Video #85 out of 200\n",
            "Video #86 out of 200\n",
            "Video #87 out of 200\n",
            "Video #88 out of 200\n",
            "Video #89 out of 200\n",
            "Video #90 out of 200\n",
            "Video #91 out of 200\n",
            "Video #92 out of 200\n",
            "Video #93 out of 200\n",
            "Failed to Upload: id07463\n",
            "Video #94 out of 200\n",
            "Video #95 out of 200\n",
            "Failed to Upload: id01210\n",
            "Video #96 out of 200\n",
            "Failed to Upload: id01995\n",
            "Video #97 out of 200\n",
            "Video #98 out of 200\n",
            "Video #99 out of 200\n",
            "Video #100 out of 200\n",
            "Video #101 out of 200\n",
            "Video #102 out of 200\n",
            "Video #103 out of 200\n",
            "Video #104 out of 200\n",
            "Video #105 out of 200\n",
            "Video #106 out of 200\n",
            "Video #107 out of 200\n",
            "Video #108 out of 200\n",
            "Video #109 out of 200\n",
            "Video #110 out of 200\n",
            "Video #111 out of 200\n",
            "Video #112 out of 200\n",
            "Video #113 out of 200\n",
            "Video #114 out of 200\n",
            "Failed to Upload: id01215\n",
            "Video #115 out of 200\n",
            "Video #116 out of 200\n",
            "Video #117 out of 200\n",
            "Video #118 out of 200\n",
            "Video #119 out of 200\n",
            "Video #120 out of 200\n",
            "Video #121 out of 200\n",
            "Video #122 out of 200\n",
            "Video #123 out of 200\n",
            "Video #124 out of 200\n",
            "Video #125 out of 200\n",
            "Video #126 out of 200\n",
            "Video #127 out of 200\n",
            "Video #128 out of 200\n",
            "Video #129 out of 200\n",
            "Video #130 out of 200\n",
            "Video #131 out of 200\n",
            "Video #132 out of 200\n",
            "Video #133 out of 200\n",
            "Failed to Upload: id00021\n",
            "Video #134 out of 200\n",
            "Video #135 out of 200\n",
            "Failed to Upload: id01099\n",
            "Video #136 out of 200\n",
            "Video #137 out of 200\n",
            "Video #138 out of 200\n",
            "Video #139 out of 200\n",
            "Video #140 out of 200\n",
            "Video #141 out of 200\n",
            "Video #142 out of 200\n",
            "Video #143 out of 200\n",
            "Video #144 out of 200\n",
            "Failed to Upload: id01933\n",
            "Video #145 out of 200\n",
            "Video #146 out of 200\n",
            "Video #147 out of 200\n",
            "Video #148 out of 200\n",
            "Video #149 out of 200\n",
            "Video #150 out of 200\n",
            "Failed to Upload: id03945\n",
            "Video #151 out of 200\n",
            "Video #152 out of 200\n",
            "Video #153 out of 200\n",
            "Video #154 out of 200\n",
            "Failed to Upload: id06591\n",
            "Video #155 out of 200\n",
            "Video #156 out of 200\n",
            "Video #157 out of 200\n",
            "Video #158 out of 200\n",
            "Video #159 out of 200\n",
            "Video #160 out of 200\n",
            "Failed to Upload: id01036\n",
            "Video #161 out of 200\n",
            "Video #162 out of 200\n",
            "Failed to Upload: id06354\n",
            "Video #163 out of 200\n",
            "Video #164 out of 200\n",
            "Video #165 out of 200\n",
            "Failed to Upload: id04222\n",
            "Video #166 out of 200\n",
            "Video #167 out of 200\n",
            "Video #168 out of 200\n",
            "Failed to Upload: id07058\n",
            "Video #169 out of 200\n",
            "Video #170 out of 200\n",
            "Video #171 out of 200\n",
            "Video #172 out of 200\n",
            "Video #173 out of 200\n",
            "Video #174 out of 200\n",
            "Video #175 out of 200\n",
            "Video #176 out of 200\n",
            "Failed to Upload: id04928\n",
            "Video #177 out of 200\n",
            "Video #178 out of 200\n",
            "Video #179 out of 200\n",
            "Video #180 out of 200\n",
            "Video #181 out of 200\n",
            "Video #182 out of 200\n",
            "Video #183 out of 200\n",
            "Video #184 out of 200\n",
            "Video #185 out of 200\n",
            "Video #186 out of 200\n",
            "Failed to Upload: id02040\n",
            "Video #187 out of 200\n",
            "Video #188 out of 200\n",
            "Video #189 out of 200\n",
            "Video #190 out of 200\n",
            "Video #191 out of 200\n",
            "Failed to Upload: id02342\n",
            "Video #192 out of 200\n",
            "Video #193 out of 200\n",
            "Video #194 out of 200\n",
            "Video #195 out of 200\n",
            "Video #196 out of 200\n",
            "Video #197 out of 200\n",
            "Video #198 out of 200\n",
            "Video #199 out of 200\n",
            "Video #200 out of 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#video_path = '/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/RealVideo-RealAudio/African/men/id00076/00109.mp4'\n",
        "#video = cv2.VideoCapture(video_path)\n",
        "\n",
        "#predictor_path = '/content/drive/MyDrive/DeepFakeDetection/model/shape_predictor_68_face_landmarks.dat'\n",
        "#detector = dlib.get_frontal_face_detector()\n",
        "#predictor = dlib.shape_predictor(predictor_path)"
      ],
      "metadata": {
        "id": "FFY6AqKG_0Cw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#audio_path = '/content/drive/MyDrive/DeepFakeDetection/data/FakeAVCeleb_v1.2/RealVideo-RealAudio/African/men/id00076/00109.wav'\n",
        "#audio, sample_rate = librosa.load(audio_path)"
      ],
      "metadata": {
        "id": "3ZqUBJjYSsfP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vid1_dlib = DlibManager(predictor, detector, video)"
      ],
      "metadata": {
        "id": "1yKfJjBb_4Sc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_lips(lip_frames, height=90, width=70):\n",
        "\n",
        "  lip_frames_resized = []\n",
        "\n",
        "  for frame in lip_frames:\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    resized_frame = cv2.resize(frame, (height, width))\n",
        "    lip_frames_resized.append(resized_frame)\n",
        "\n",
        "  lip_frames_resized = np.array(lip_frames_resized)\n",
        "  lip_frames_resized = lip_frames_resized.reshape(lip_frames_resized.shape[0], lip_frames_resized.shape[1]*lip_frames_resized.shape[2])\n",
        "\n",
        "  return lip_frames_resized\n"
      ],
      "metadata": {
        "id": "BRq7sHEApa4q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resize all the lip frames to 70 x 90\n",
        "#lip_frames_resized = []\n",
        "#for frame in vid1_dlib.lip_frames:\n",
        "#  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "#  resized_frame = cv2.resize(frame, (90, 70))\n",
        "#  lip_frames_resized.append(resized_frame)\n",
        "#lip_frames_resized = np.array(lip_frames_resized)"
      ],
      "metadata": {
        "id": "l40iR1mk_95A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(data):\n",
        "  return (data - np.mean(data))/np.std(data)"
      ],
      "metadata": {
        "id": "SvdKSr5ukOKq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(training_video_details, num_components):\n",
        "  \n",
        "  lips_data = None\n",
        "  X  = None\n",
        "  y = None\n",
        "\n",
        "  for idx, training_video_data in enumerate(training_video_details):\n",
        "    if len(training_video_data) > 4:\n",
        "      for item in training_video_data:\n",
        "        print(item)\n",
        "    id, lip_frames, audio, sample_rate = training_video_data\n",
        "\n",
        "    lip_frames_resized = preprocess_lips(lip_frames)\n",
        "    #lip_frames_resized = lip_frames_resized.reshape(lip_frames_resized.shape[0], lip_frames_resized.shape[1]*lip_frames_resized.shape[2])\n",
        "    \n",
        "    row_count = lip_frames_resized.shape[0]\n",
        "\n",
        "    mfcc_features = librosa.feature.mfcc(y=audio, hop_length=int(sample_rate*librosa.get_duration(audio)/row_count)).T[:row_count, :]\n",
        "    mfcc_features = normalize(mfcc_features)\n",
        "\n",
        "    if isinstance(lips_data, type(None)):\n",
        "      lips_data = lip_frames_resized\n",
        "      y = mfcc_features\n",
        "    else:\n",
        "      lips_data = np.vstack((lips_data, lip_frames_resized))\n",
        "      y = np.vstack((y, mfcc_features))\n",
        "\n",
        "  \n",
        "  lips_data_mean = np.mean(lips_data, axis=0)\n",
        "  lips_data_centered = lips_data - lips_data_mean\n",
        "\n",
        "  pca = PCA()\n",
        "  pca_lip_frames = pca.fit_transform(lips_data_centered)\n",
        "\n",
        "  eigenfaces = pca.components_[:num_components]\n",
        "  weights = np.dot(lips_data_centered, eigenfaces.T)\n",
        "\n",
        "  X = weights\n",
        "\n",
        "  return X, y, lips_data_mean, pca\n"
      ],
      "metadata": {
        "id": "H7h8MfxSr6gG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, lips_data_mean, pca = generate_training_data(training_videos_details, 10)"
      ],
      "metadata": {
        "id": "-C99Ys5Cy7We"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_models(X, y):\n",
        "\n",
        "  num_coef = y.shape[1]\n",
        "  models = []\n",
        "  for i in range(num_coef):\n",
        "    assert X.shape[0] == y[:, i].shape[0], 'X and y must have the same number of rows'\n",
        "    model = LinearRegression().fit(X, y[:, i])\n",
        "    models.append(model)\n",
        "\n",
        "  return models"
      ],
      "metadata": {
        "id": "PNikq-HRS4cI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = train_models(X, y)"
      ],
      "metadata": {
        "id": "CIzqbjmJTh4d"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_videos_details = []\n",
        "failed_testing_videos_dlib = []\n",
        "for idx, testing_id in enumerate(testing_ids):\n",
        "  print(f'Video #{idx+1} out of {len(testing_ids)}')\n",
        "\n",
        "  real_video_path = metadata[(metadata['source'] == testing_id) & (metadata['method'] == 'real')]['full_path'].values[0]\n",
        "  fake_video_path = metadata[(metadata['source'] == testing_id) & (metadata['method']=='wav2lip')].sample(1)['full_path'].values[0]\n",
        "\n",
        "  real_video = cv2.VideoCapture(real_video_path)\n",
        "  fake_video = cv2.VideoCapture(fake_video_path)\n",
        "\n",
        "  real_audio_path = real_video_path.replace('.mp4', '.wav')\n",
        "  fake_audio_path = fake_video_path.replace('.mp4', '.wav')\n",
        "\n",
        "  real_audio, real_sample_rate = librosa.load(real_audio_path)\n",
        "  fake_audio, fake_sample_rate = librosa.load(fake_audio_path)\n",
        "\n",
        "  try:\n",
        "    real_dlib_video = DlibManager(predictor, detector, real_video)\n",
        "    fake_dlib_video = DlibManager(predictor, detector, fake_video)\n",
        "    testing_videos_details.append((testing_id, real_dlib_video.lip_frames, fake_dlib_video.lip_frames, real_audio, fake_audio, real_sample_rate, fake_sample_rate, real_video_path, fake_video_path))\n",
        "\n",
        "  except:\n",
        "    print(f'Failed to Upload: {testing_id}')\n",
        "    failed_testing_videos_dlib.append((real_video_path, fake_video_path))\n",
        "\n",
        "  real_video.release()\n",
        "  fake_video.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mchZU50aNqpk",
        "outputId": "2fa64985-972c-40e4-f8ec-3e1e29aa3a75"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video #1 out of 50\n",
            "Failed to Upload: id00761\n",
            "Video #2 out of 50\n",
            "Failed to Upload: id01392\n",
            "Video #3 out of 50\n",
            "Video #4 out of 50\n",
            "Video #5 out of 50\n",
            "Failed to Upload: id01717\n",
            "Video #6 out of 50\n",
            "Failed to Upload: id02005\n",
            "Video #7 out of 50\n",
            "Video #8 out of 50\n",
            "Video #9 out of 50\n",
            "Video #10 out of 50\n",
            "Video #11 out of 50\n",
            "Video #12 out of 50\n",
            "Video #13 out of 50\n",
            "Video #14 out of 50\n",
            "Video #15 out of 50\n",
            "Video #16 out of 50\n",
            "Failed to Upload: id00126\n",
            "Video #17 out of 50\n",
            "Video #18 out of 50\n",
            "Video #19 out of 50\n",
            "Video #20 out of 50\n",
            "Video #21 out of 50\n",
            "Video #22 out of 50\n",
            "Video #23 out of 50\n",
            "Video #24 out of 50\n",
            "Failed to Upload: id06535\n",
            "Video #25 out of 50\n",
            "Video #26 out of 50\n",
            "Video #27 out of 50\n",
            "Video #28 out of 50\n",
            "Video #29 out of 50\n",
            "Failed to Upload: id00183\n",
            "Video #30 out of 50\n",
            "Video #31 out of 50\n",
            "Video #32 out of 50\n",
            "Video #33 out of 50\n",
            "Video #34 out of 50\n",
            "Video #35 out of 50\n",
            "Video #36 out of 50\n",
            "Video #37 out of 50\n",
            "Video #38 out of 50\n",
            "Video #39 out of 50\n",
            "Failed to Upload: id03205\n",
            "Video #40 out of 50\n",
            "Video #41 out of 50\n",
            "Video #42 out of 50\n",
            "Video #43 out of 50\n",
            "Video #44 out of 50\n",
            "Video #45 out of 50\n",
            "Video #46 out of 50\n",
            "Video #47 out of 50\n",
            "Video #48 out of 50\n",
            "Video #49 out of 50\n",
            "Video #50 out of 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_test_data(testing_video_details, pca, lips_data_mean, models, num_components=10, debug_mode=False):\n",
        "\n",
        "  real_video_error = []\n",
        "  fake_video_error = []\n",
        "\n",
        "  for idx, testing_video in enumerate(testing_video_details):\n",
        "\n",
        "    real_mfcc_errors = []\n",
        "    fake_mfcc_errors = []\n",
        "\n",
        "    testing_id, real_lip_frames, fake_lip_frames, real_audio, fake_audio, real_sample_rate, fake_sample_rate, real_video_path, fake_video_path = testing_video\n",
        "\n",
        "    if debug_mode:\n",
        "      print()\n",
        "      print('RUNNING TESTING FOR: ', testing_id)\n",
        "      print('Real Video Path: ', real_video_path)\n",
        "      print('Fake Video Path: ', fake_video_path)\n",
        "      print('--------------------------------------------')\n",
        "      print('--------------------------------------------')\n",
        "\n",
        "    if debug_mode:\n",
        "      print('Num of Items in Testing Video: ', len(testing_video))\n",
        "      #print('Testing Video Items: ', testing_video)\n",
        "\n",
        "    real_lip_frames_resized = preprocess_lips(real_lip_frames)\n",
        "    fake_lip_frames_resized = preprocess_lips(fake_lip_frames)\n",
        "\n",
        "    if debug_mode:\n",
        "      print('LIP FRAME SHAPES')\n",
        "      print('Real Lip Frames: ', real_lip_frames_resized.shape)\n",
        "      print('Fake Lip Frames: ', fake_lip_frames_resized.shape)\n",
        "      print('--------------------------------------------')\n",
        "\n",
        "    real_row_count = real_lip_frames_resized.shape[0]\n",
        "    fake_row_count = fake_lip_frames_resized.shape[0]\n",
        "\n",
        "    real_duration = librosa.get_duration(real_audio)\n",
        "    fake_duration = librosa.get_duration(fake_audio)\n",
        "\n",
        "    real_mfcc_features = librosa.feature.mfcc(y=real_audio, hop_length=int(real_sample_rate*real_duration/real_row_count)).T[:real_row_count, :]\n",
        "    real_mfcc_features = normalize(real_mfcc_features)\n",
        "    fake_mfcc_features = librosa.feature.mfcc(y=fake_audio, hop_length=int(fake_sample_rate*fake_duration/fake_row_count)).T[:fake_row_count, :]\n",
        "    fake_mfcc_features = normalize(fake_mfcc_features)\n",
        "\n",
        "    if debug_mode:\n",
        "      print('ORIGINAL MFCC FRAME SHAPES')\n",
        "      print('Real MFCC Frames: ', real_mfcc_features.shape)\n",
        "      print('Real Sample Rate:', real_sample_rate)\n",
        "      print('Real Duration: ', real_duration)\n",
        "      print('Real Frame Count: ', real_row_count)\n",
        "      print('Fake MFCC Frames: ', fake_mfcc_features.shape)\n",
        "      print('Fake Sample Rate:', fake_sample_rate)\n",
        "      print('Fake Duration: ', fake_duration)\n",
        "      print('Fake Frame Count: ', fake_row_count)\n",
        "      print('--------------------------------------------')\n",
        "\n",
        "\n",
        "    real_lips_centered = real_lip_frames_resized - lips_data_mean\n",
        "    fake_lips_centered = fake_lip_frames_resized - lips_data_mean\n",
        "\n",
        "    real_pca_lip_frames = pca.transform(real_lips_centered)\n",
        "    fake_pca_lip_frames = pca.transform(fake_lips_centered)\n",
        "\n",
        "\n",
        "    eigenfaces = pca.components_[:num_components]\n",
        "    real_weights = np.dot(real_lips_centered, eigenfaces.T)\n",
        "    fake_weights = np.dot(fake_lips_centered, eigenfaces.T)\n",
        "\n",
        "    X_real = real_weights\n",
        "    X_fake = fake_weights\n",
        "    y_real = real_mfcc_features\n",
        "    y_fake = fake_mfcc_features\n",
        "\n",
        "\n",
        "    if debug_mode:\n",
        "      print('TRAINING DATA SHAPES')\n",
        "      print('X Real Shape:', X_real.shape)\n",
        "      print('X Fake Shape:', X_fake.shape)\n",
        "      print('y Real Shape:', y_real.shape)\n",
        "      print('y Fake Shape:', y_fake.shape)\n",
        "      print('--------------------------------------------')\n",
        "\n",
        "    for idx, model in enumerate(models):\n",
        "      y_real_pred = model.predict(X_real)\n",
        "      y_fake_pred = model.predict(X_fake)\n",
        "\n",
        "      real_err = np.sqrt(mean_squared_error(y_true=y_real[:, idx], y_pred=y_real_pred))/len(y_real_pred)\n",
        "      fake_err = np.sqrt(mean_squared_error(y_true=y_fake[:, idx], y_pred=y_fake_pred))/len(y_fake_pred)\n",
        "\n",
        "      real_mfcc_errors.append(real_err)\n",
        "      fake_mfcc_errors.append(fake_err)\n",
        "\n",
        "    real_video_error.append(np.mean(real_mfcc_errors))\n",
        "    fake_video_error.append(np.mean(fake_mfcc_errors))\n",
        "\n",
        "\n",
        "  return real_video_error, fake_video_error\n"
      ],
      "metadata": {
        "id": "n1TJqSOszk3e"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_video_error, fake_video_error = eval_test_data(testing_videos_details, pca, lips_data_mean, models, 10, False)"
      ],
      "metadata": {
        "id": "2n4T6N3taoSj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fake_video_error)"
      ],
      "metadata": {
        "id": "-f0MNPZSCYBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(fake_video_error, label='Fake', color='blue')\n",
        "sns.histplot(real_video_error, label='Real', color='red')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "UrhJ8hPTeebI",
        "outputId": "75b891b3-9259-42ab-8cf6-b118e8b29ae1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape_lip_frames = lip_frames_resized.reshape(lip_frames_resized.shape[0], lip_frames_resized.shape[1]*lip_frames_resized.shape[2])\n"
      ],
      "metadata": {
        "id": "7MjQDhGzASQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scalar = StandardScaler()\n",
        "#centered_lip_frames = scalar.fit_transform(reshape_lip_frames)\n",
        "\n",
        "#avg_lip_frames = np.mean(reshape_lip_frames, axis=0)\n",
        "#centered_lip_frames = reshape_lip_frames - avg_lip_frames"
      ],
      "metadata": {
        "id": "h1aCxyvKCqcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pca = PCA()\n",
        "#pca_lip_frames = pca.fit_transform(centered_lip_frames)"
      ],
      "metadata": {
        "id": "eHL-cc9IC0NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random_samples = np.random.choice(np.arange(0, reshape_lip_frames.shape[0]), 5)\n",
        "#random_samples"
      ],
      "metadata": {
        "id": "UFZC6xFpE-zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def reconstruction(pca, num_components, centered_data, mean, image_idx, height=70, width=90):\n",
        "#  eigenfaces = pca.components_[:num_components]\n",
        "#  samples, features = centered_data.shape\n",
        "#  weights = np.dot(centered_data, eigenfaces.T)\n",
        "#  recovered_image = (np.dot(weights[image_idx,:], eigenfaces)+mean).reshape(height, width)\n",
        "#  return recovered_image\n",
        "\n"
      ],
      "metadata": {
        "id": "cKGxEvy-HP37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fig, axes = plt.subplots(5,2,sharex=True,sharey=True,figsize=(8,10))\n",
        "#fig.suptitle('Eigenface Count: 1', fontsize=16)\n",
        "#for idx, sample in enumerate(random_samples):\n",
        "#  orig = vid1_dlib.lip_frames[sample]\n",
        "#  reconstructed = reconstruction(pca, 1, centered_lip_frames, avg_lip_frames, sample)\n",
        "#  axes[idx, 0].imshow(orig)\n",
        "#  axes[idx, 1].imshow(reconstructed, cmap=\"gray\")\n",
        "#plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "FBhOBoYTHAX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "fig, axes = plt.subplots(5,2,sharex=True,sharey=True,figsize=(8,10))\n",
        "fig.suptitle('Eigenface Count: 10', fontsize=16)\n",
        "for idx, sample in enumerate(random_samples):\n",
        "  orig = vid1_dlib.lip_frames[sample]\n",
        "  reconstructed = reconstruction(pca, 10, centered_lip_frames, avg_lip_frames, sample)\n",
        "  axes[idx, 0].imshow(orig)\n",
        "  axes[idx, 1].imshow(reconstructed, cmap=\"gray\")\n",
        "plt.show()\n",
        "'''  "
      ],
      "metadata": {
        "id": "NDX69bvtM7VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "mfcc_features = librosa.feature.mfcc(y=audio, hop_length=int(sample_rate*librosa.get_duration(audio)/251)).T[:251, :]\n",
        "'''"
      ],
      "metadata": {
        "id": "pUt8FycOOgQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "coef_one_mfcc = mfcc_features[:, 0].reshape(251, 1)\n",
        "'''"
      ],
      "metadata": {
        "id": "Ka-PktduTNCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#weights.shape"
      ],
      "metadata": {
        "id": "ePIDL0n9X2SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#coef_one_mfcc.shape\n"
      ],
      "metadata": {
        "id": "de0zdR8VX4K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "eigenfaces = pca.components_[:10]\n",
        "samples, features = centered_lip_frames.shape\n",
        "weights = np.dot(centered_lip_frames, eigenfaces.T)\n",
        "\n",
        "train_test_data = np.hstack((weights, coef_one_mfcc.reshape(251, 1)))\n",
        "'''"
      ],
      "metadata": {
        "id": "N86oeeA8Ujgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(weights, coef_one_mfcc, test_size=0.15, random_state=12)"
      ],
      "metadata": {
        "id": "ypEk_8StWCLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "err = np.sqrt(mean_squared_error(y_true=y_test, y_pred=pred))/len(pred)\n",
        "print(err)\n",
        "'''"
      ],
      "metadata": {
        "id": "UbhXQwy4WUPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def train(X, y)"
      ],
      "metadata": {
        "id": "iWffI7VThrRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gA_NRYDJfbKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def evaluate(X_test, y_):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=12)\n",
        "\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  pred = model.predict(X_test)\n",
        "  err = np.sqrt(mean_squared_error(y_true=y_test, y_pred=pred))/len(pred)\n",
        "\n",
        "  return pred, err\n",
        "'''\n"
      ],
      "metadata": {
        "id": "elmNUPsIgH81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "paM7O2PLaZ2R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}