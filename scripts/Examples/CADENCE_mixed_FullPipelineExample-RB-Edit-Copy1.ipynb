{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1754ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.24.3) or chardet (5.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-05-18 04:39:57.876903: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 04:39:57.988770: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-18 04:39:58.546449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-18 04:39:58.546515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-18 04:39:58.546520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[NeMo W 2023-05-18 04:39:59 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-05-18 04:39:59 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-05-18 04:40:00 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-05-18 04:40:00 nemo_logging:349] /home/ubuntu/miniconda3/envs/nemo/lib/python3.8/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2023-05-18 04:40:00 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-05-18 04:40:00 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-05-18 04:40:00 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-05-18 04:40:00 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-05-18 04:40:00 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/MultiModalDeepFake\")\n",
    "import nemo.collections.asr as nemo_asr \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704a1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from packages.LJDataLoader import LJDataLoader\n",
    "from packages.AudioEmbeddingsManager import AudioEmbeddingsManager\n",
    "from packages.ModelManager import ModelManager\n",
    "from packages.CadenceModelManager import CadenceModelManager\n",
    "import packages.AnalysisManager as am\n",
    "from packages.SmileFeatureManager import SmileFeatureManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99d6b71-3cd2-40a0-a439-0f579013eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split(fake_cols, file_path):\n",
    "\n",
    "    \n",
    "    loader = LJDataLoader(data_path=file_path)\n",
    "    loader.sample(0.1)\n",
    "    loader.splitData()\n",
    "\n",
    "    source_architectures = ['Full_Band_MelGan', 'HifiGan', 'MelGan', 'MelGanLarge', 'Multi_Band_MelGan', 'Parallel_WaveGan', 'Waveglow']\n",
    "    new_col_name = 'RandWaveFake'\n",
    "    loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)\n",
    "    \n",
    "    source_architectures = ['RandWaveFake', 'ElevenLabs', 'UberDuck']\n",
    "    new_col_name = 'Fake'\n",
    "    loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)\n",
    "\n",
    "    #data_df = loader.generateFinalDataFrame(real_col='Real', fake_cols=['RandWaveFake', 'ElevenLabs', 'UberDuck'])\n",
    "    data_df = loader.generateFinalDataFrame(real_col='Real', fake_cols=fake_cols)\n",
    "    \n",
    "    train_count = data_df[data_df['type'] == 'train'].shape[0]\n",
    "    dev_count = data_df[data_df['type'] == 'dev'].shape[0]\n",
    "    test_count = data_df[data_df['type'] == 'test'].shape[0]\n",
    "\n",
    "    print(f'# of Train instances: {train_count}')\n",
    "    print(f'# of Dev instances: {dev_count}')\n",
    "    print(f'# of Test instances: {test_count}')\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73bb9087-a587-4b7f-a270-031cf55bd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data_df):\n",
    "    speaker_model = nemo_asr.models.EncDecSpeakerLabelModel.from_pretrained(model_name='titanet_large')\n",
    "    embedding_manager = AudioEmbeddingsManager(model=speaker_model, data=data_df)\n",
    "    em_feature_df, em_feature_cols = embedding_manager.generateFeatureDf()\n",
    "    \n",
    "    cadence_manager = CadenceModelManager(data_df)\n",
    "    cad_feature_df, cad_feature_cols, scalar =  cadence_manager.run_cadence_feature_extraction_pipeline() # Add param for load features or not\n",
    "    \n",
    "    smile_manager = SmileFeatureManager(data_df)\n",
    "    os_binary_feature_df, os_binary_feature_cols = smile_manager.generateFeatureDf('random_forest', label_type='binary')\n",
    "    os_multiclass_feature_df, os_multiclass_feature_cols = smile_manager.generateFeatureDf('random_forest', label_type='multiclass')\n",
    "    \n",
    "    feature_store = {}\n",
    "    feature_store['titanet'] = (em_feature_df, em_feature_cols)\n",
    "    feature_store['openSmile_binary'] = (os_binary_feature_df, os_binary_feature_cols)\n",
    "    feature_store['openSmile_multiclass'] = (os_multiclass_feature_df, os_multiclass_feature_cols)\n",
    "    feature_store['cadence'] = (cad_feature_df, cad_feature_cols)\n",
    "    \n",
    "    return feature_store\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f444f8df-6f02-4f76-869d-a8722e7c5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(feature_store, fake_cols):\n",
    "    results_cols = ['model', 'fake_cols', 'label_type', 'acc', 'cls_acc', 'loss']\n",
    "    results = pd.DataFrame(columns=results_cols)\n",
    "    \n",
    "    for label_type in ['label', 'multiclass_label']:\n",
    "        for k, v in feature_store.items():\n",
    "            model_manager = ModelManager('logreg', v[0], v[1], merge_train_dev=True)\n",
    "            model_manager.trainPredict(label_col=label_type)\n",
    "            print(model_manager.class_accuracy)\n",
    "            results = results.append(pd.DataFrame({'model':[k], 'label_type':[label_type], 'fake_cols':[fake_cols], 'acc':[model_manager.accuracy], 'cls_acc':[model_manager.class_accuracy],  'loss':[model_manager.log_loss_value]}))\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c8a77a-0903-47d6-a059-9f4101f8cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fake_cols, metadata_path, name):\n",
    "    data_df = generate_split(fake_cols, metadata_path)\n",
    "    feature_store = generate_features(data_df)\n",
    "    results = train_eval(feature_store, fake_cols)\n",
    "    results.to_csv(f'/home/ubuntu/data/results/{name}.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7da5b3-6cc2-4945-b028-b77a074181c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "#run(['ElevenLabs'], file_path, '16KHz_ElevenLabs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f191bb2-eb2b-44f5-9812-512213063804",
   "metadata": {},
   "source": [
    "For the columns, we want:\n",
    "- Which dataset are we using\n",
    "- What are the fake cols\n",
    "- Binary/Multi-Class\n",
    "- Feature Generation Method\n",
    "- Accuracy\n",
    "- Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e67b5523-356f-4c93-8643-c8db29057b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "#run(['UberDuck'], file_path, '16KHz_UberDuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c323a8b9-1d03-45f3-9161-f289f2795f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "#run(['UberDuck', 'ElevenLabs'], file_path, '16KHz_ElevenLabs_and_UberDuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95bd03da-e36e-4ce6-909c-d519188eb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Train instances: 3132\n",
      "# of Dev instances: 1044\n",
      "# of Test instances: 1048\n",
      "[NeMo I 2023-05-18 04:40:03 cloud:56] Found existing object /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo.\n",
      "[NeMo I 2023-05-18 04:40:03 cloud:62] Re-using file from: /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo\n",
      "[NeMo I 2023-05-18 04:40:03 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-05-18 04:40:03 modelPT:156] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 3\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-05-18 04:40:03 modelPT:163] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    time_length: 3\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-05-18 04:40:03 label_models:126] Setting angular: true/false in decoder is deprecated and will be removed in 1.13 version, use specific loss with _target_\n",
      "[NeMo I 2023-05-18 04:40:03 features:267] PADDING: 16\n",
      "[NeMo I 2023-05-18 04:40:04 save_restore_connector:243] Model EncDecSpeakerLabelModel was successfully restored from /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing amplitudes\n",
      "Window size: 50\n",
      "Truncating audio 100/5224 (2%)\n",
      "Truncating audio 200/5224 (4%)\n",
      "Truncating audio 300/5224 (6%)\n",
      "Truncating audio 400/5224 (8%)\n",
      "Truncating audio 500/5224 (10%)\n",
      "Truncating audio 600/5224 (11%)\n",
      "Truncating audio 700/5224 (13%)\n",
      "Truncating audio 800/5224 (15%)\n",
      "Truncating audio 900/5224 (17%)\n",
      "Truncating audio 1000/5224 (19%)\n",
      "Truncating audio 1100/5224 (21%)\n",
      "Truncating audio 1200/5224 (23%)\n",
      "Truncating audio 1300/5224 (25%)\n",
      "Truncating audio 1400/5224 (27%)\n",
      "Truncating audio 1500/5224 (29%)\n",
      "Truncating audio 1600/5224 (31%)\n",
      "Truncating audio 1700/5224 (33%)\n",
      "Truncating audio 1800/5224 (34%)\n",
      "Truncating audio 1900/5224 (36%)\n",
      "Truncating audio 2000/5224 (38%)\n",
      "Truncating audio 2100/5224 (40%)\n",
      "Truncating audio 2200/5224 (42%)\n",
      "Truncating audio 2300/5224 (44%)\n",
      "Truncating audio 2400/5224 (46%)\n",
      "Truncating audio 2500/5224 (48%)\n",
      "Truncating audio 2600/5224 (50%)\n",
      "Truncating audio 2700/5224 (52%)\n",
      "Truncating audio 2800/5224 (54%)\n",
      "Truncating audio 2900/5224 (56%)\n",
      "Truncating audio 3000/5224 (57%)\n",
      "Truncating audio 3100/5224 (59%)\n",
      "Truncating audio 3200/5224 (61%)\n",
      "Truncating audio 3300/5224 (63%)\n",
      "Truncating audio 3400/5224 (65%)\n",
      "Truncating audio 3500/5224 (67%)\n",
      "Truncating audio 3600/5224 (69%)\n",
      "Truncating audio 3700/5224 (71%)\n",
      "Truncating audio 3800/5224 (73%)\n",
      "Truncating audio 3900/5224 (75%)\n",
      "Truncating audio 4000/5224 (77%)\n",
      "Truncating audio 4100/5224 (78%)\n",
      "Truncating audio 4200/5224 (80%)\n",
      "Truncating audio 4300/5224 (82%)\n",
      "Truncating audio 4400/5224 (84%)\n",
      "Truncating audio 4500/5224 (86%)\n",
      "Truncating audio 4600/5224 (88%)\n",
      "Truncating audio 4700/5224 (90%)\n",
      "Truncating audio 4800/5224 (92%)\n",
      "Truncating audio 4900/5224 (94%)\n",
      "Truncating audio 5000/5224 (96%)\n",
      "Truncating audio 5100/5224 (98%)\n",
      "Truncating audio 5200/5224 (100%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-05-18 04:44:21 nemo_logging:349] /home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "      ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "    \n",
      "[NeMo W 2023-05-18 04:44:21 nemo_logging:349] /home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "      arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "    \n",
      "[NeMo W 2023-05-18 04:44:21 nemo_logging:349] /home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "      ret = ret.dtype.type(ret / rcount)\n",
      "    \n",
      "[NeMo W 2023-05-18 04:44:21 nemo_logging:349] /home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "      return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "    \n",
      "[NeMo W 2023-05-18 04:44:21 nemo_logging:349] /home/ubuntu/.local/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "      ret = ret.dtype.type(ret / rcount)\n",
      "    \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mElevenLabs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUberDuck\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRandWaveFake\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m16KHz_Mix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(fake_cols, metadata_path, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(fake_cols, metadata_path, name):\n\u001b[1;32m      2\u001b[0m     data_df \u001b[38;5;241m=\u001b[39m generate_split(fake_cols, metadata_path)\n\u001b[0;32m----> 3\u001b[0m     feature_store \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     results \u001b[38;5;241m=\u001b[39m train_eval(feature_store, fake_cols)\n\u001b[1;32m      5\u001b[0m     results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ubuntu/data/results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mgenerate_features\u001b[0;34m(data_df)\u001b[0m\n\u001b[1;32m      4\u001b[0m em_feature_df, em_feature_cols \u001b[38;5;241m=\u001b[39m embedding_manager\u001b[38;5;241m.\u001b[39mgenerateFeatureDf()\n\u001b[1;32m      6\u001b[0m cadence_manager \u001b[38;5;241m=\u001b[39m CadenceModelManager(data_df)\n\u001b[0;32m----> 7\u001b[0m cad_feature_df, cad_feature_cols, scalar \u001b[38;5;241m=\u001b[39m  \u001b[43mcadence_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cadence_feature_extraction_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Add param for load features or not\u001b[39;00m\n\u001b[1;32m      9\u001b[0m smile_manager \u001b[38;5;241m=\u001b[39m SmileFeatureManager(data_df)\n\u001b[1;32m     10\u001b[0m os_binary_feature_df, os_binary_feature_cols \u001b[38;5;241m=\u001b[39m smile_manager\u001b[38;5;241m.\u001b[39mgenerateFeatureDf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m'\u001b[39m, label_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/MultiModalDeepFake/packages/CadenceModelManager.py:61\u001b[0m, in \u001b[0;36mCadenceModelManager.run_cadence_feature_extraction_pipeline\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_audio_amplitudes()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Hyperparam tune \u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m window_size, silence_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparam_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Save down the best params and proceed \u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m## RB COMMENT: DO WE NEED THE START_IDS AND END_IDS? NOT SEEING THEM USED ANYWHERE ELSE\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Truncate silences\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTruncating silences\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/MultiModalDeepFake/packages/CadenceModelManager.py:417\u001b[0m, in \u001b[0;36mCadenceModelManager.hyperparam_search\u001b[0;34m(self, window_size_options, silence_threshold_options, model, scaler)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m#if nans in full_df:\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m#    \u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m#    continue\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 417\u001b[0m     clf \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m     score \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mscore(X_dev, y_dev)\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindowsize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, silence_threshold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msilence_threshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "run(['ElevenLabs', 'UberDuck', 'RandWaveFake'], file_path, '16KHz_Mix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff1f08-e8c3-4531-bfd3-3cb455946e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "#run(['ElevenLabs'], file_path, '16KHz_ElevenLabs_Laundered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06322cae-5e05-4df0-a309-d8b77dc96ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "#run(['UberDuck'], file_path, '16KHz_UberDuck_Laundered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab235243-e6e4-4d01-a91d-9e9ed45eecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "#run(['UberDuck', 'ElevenLabs'], file_path, '16KHz_ElevenLabs_and_UberDuck_Laundered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b87d4-d366-48de-9c5f-f0648069f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "#run(['ElevenLabs', 'UberDuck', 'RandWaveFake'], file_path, '16KHz_Mix_Laundered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a302eee-3c3a-4e71-9241-4329946bfc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "nemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
