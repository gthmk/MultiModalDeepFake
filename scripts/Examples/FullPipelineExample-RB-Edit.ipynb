{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1754ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 10:26:01.048929: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 10:26:01.220446: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-07 10:26:02.101370: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-07 10:26:02.101444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-07 10:26:02.101449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[NeMo W 2023-07-07 10:26:04 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-07-07 10:26:04 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-07 10:26:04 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-07 10:26:05 nemo_logging:349] /home/ubuntu/miniconda3/envs/nemo/lib/python3.8/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2023-07-07 10:26:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-07 10:26:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-07 10:26:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-07 10:26:05 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-07-07 10:26:05 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/MultiModalDeepFake\")\n",
    "import nemo.collections.asr as nemo_asr \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704a1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.LJDataLoader import LJDataLoader\n",
    "from packages.AudioEmbeddingsManager import AudioEmbeddingsManager\n",
    "from packages.ModelManager import ModelManager\n",
    "from packages.CadenceModelManager import CadenceModelManager\n",
    "import packages.AnalysisManager as am\n",
    "from packages.SmileFeatureManager import SmileFeatureManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ee0de13-da36-40bc-98ee-d685da1fafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LJDataLoader(data_path=file_path, filter_cols=['ElevenLabsCloneClip'])\n",
    "loader.splitData()\n",
    "\n",
    "source_architectures = ['Full_Band_MelGan', 'HifiGan', 'MelGan', 'MelGanLarge', 'Multi_Band_MelGan', 'Parallel_WaveGan', 'Waveglow']\n",
    "new_col_name = 'RandWaveFake'\n",
    "loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)\n",
    "\n",
    "source_architectures = ['ElevenLabs', 'UberDuck']\n",
    "new_col_name = 'EL_UD_Fake'\n",
    "loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)\n",
    "\n",
    "source_architectures = ['RandWaveFake', 'ElevenLabs', 'UberDuck']\n",
    "new_col_name = 'Fake'\n",
    "loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99d6b71-3cd2-40a0-a439-0f579013eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split(fake_cols, file_path):\n",
    "\n",
    "    \n",
    "    loader = LJDataLoader(data_path=file_path, filter_cols=['ElevenLabsCloneClip'])\n",
    "    loader.splitData()\n",
    "\n",
    "    source_architectures = ['Full_Band_MelGan', 'HifiGan', 'MelGan', 'MelGanLarge', 'Multi_Band_MelGan', 'Parallel_WaveGan', 'Waveglow']\n",
    "    new_col_name = 'RandWaveFake'\n",
    "    loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)\n",
    "    \n",
    "    source_architectures = ['ElevenLabs', 'UberDuck']\n",
    "    new_col_name = 'EL_UD_Fake'\n",
    "    loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)\n",
    "    \n",
    "    source_architectures = ['RandWaveFake', 'ElevenLabs', 'UberDuck']\n",
    "    new_col_name = 'Fake'\n",
    "    loader.selectRandomArchitecture(target_col=new_col_name, source_cols=source_architectures)\n",
    "\n",
    "    #data_df = loader.generateFinalDataFrame(real_col='Real', fake_cols=['RandWaveFake', 'ElevenLabs', 'UberDuck'])\n",
    "    data_df = loader.generateFinalDataFrame(real_col='Real', fake_cols=fake_cols)\n",
    "    \n",
    "    train_count = data_df[data_df['type'] == 'train'].shape[0]\n",
    "    dev_count = data_df[data_df['type'] == 'dev'].shape[0]\n",
    "    test_count = data_df[data_df['type'] == 'test'].shape[0]\n",
    "\n",
    "    print(f'# of Train instances: {train_count}')\n",
    "    print(f'# of Dev instances: {dev_count}')\n",
    "    print(f'# of Test instances: {test_count}')\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cbb79-ba35-405b-8f29-67ce99a5b9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea44a1bf-3349-40bd-b9ed-9398b42e747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Train instances: 78330\n",
      "# of Dev instances: 26110\n",
      "# of Test instances: 26110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>multiclass_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>LJ034-0127</td>\n",
       "      <td>Real</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>LJ024-0083</td>\n",
       "      <td>Real</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>LJ041-0054</td>\n",
       "      <td>Real</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>LJ038-0025</td>\n",
       "      <td>Real</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>LJ011-0210</td>\n",
       "      <td>Real</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130545</th>\n",
       "      <td>test</td>\n",
       "      <td>LJ013-0236</td>\n",
       "      <td>Waveglow</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/generated_audi...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130546</th>\n",
       "      <td>test</td>\n",
       "      <td>LJ028-0195</td>\n",
       "      <td>Waveglow</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/generated_audi...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130547</th>\n",
       "      <td>test</td>\n",
       "      <td>LJ012-0142</td>\n",
       "      <td>Waveglow</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/generated_audi...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130548</th>\n",
       "      <td>test</td>\n",
       "      <td>LJ037-0038</td>\n",
       "      <td>Waveglow</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/generated_audi...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130549</th>\n",
       "      <td>test</td>\n",
       "      <td>LJ019-0290</td>\n",
       "      <td>Waveglow</td>\n",
       "      <td>/home/ubuntu/data/wavefake_data/generated_audi...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130550 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         type          id architecture  \\\n",
       "0       train  LJ034-0127         Real   \n",
       "1       train  LJ024-0083         Real   \n",
       "2       train  LJ041-0054         Real   \n",
       "3       train  LJ038-0025         Real   \n",
       "4       train  LJ011-0210         Real   \n",
       "...       ...         ...          ...   \n",
       "130545   test  LJ013-0236     Waveglow   \n",
       "130546   test  LJ028-0195     Waveglow   \n",
       "130547   test  LJ012-0142     Waveglow   \n",
       "130548   test  LJ037-0038     Waveglow   \n",
       "130549   test  LJ019-0290     Waveglow   \n",
       "\n",
       "                                                     path  label  \\\n",
       "0       /home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...      0   \n",
       "1       /home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...      0   \n",
       "2       /home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...      0   \n",
       "3       /home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...      0   \n",
       "4       /home/ubuntu/data/wavefake_data/LJSpeech_1.1/w...      0   \n",
       "...                                                   ...    ...   \n",
       "130545  /home/ubuntu/data/wavefake_data/generated_audi...      1   \n",
       "130546  /home/ubuntu/data/wavefake_data/generated_audi...      1   \n",
       "130547  /home/ubuntu/data/wavefake_data/generated_audi...      1   \n",
       "130548  /home/ubuntu/data/wavefake_data/generated_audi...      1   \n",
       "130549  /home/ubuntu/data/wavefake_data/generated_audi...      1   \n",
       "\n",
       "        multiclass_label  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "130545                 9  \n",
       "130546                 9  \n",
       "130547                 9  \n",
       "130548                 9  \n",
       "130549                 9  \n",
       "\n",
       "[130550 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_split(['ElevenLabs', 'UberDuck', 'Full_Band_MelGan', 'HifiGan', 'MelGan', 'MelGanLarge', 'Multi_Band_MelGan', 'Parallel_WaveGan', 'Waveglow'], '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14a65cb-59cf-4e19-b777-80bf153e28a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "architecture       label\n",
       "ElevenLabs         1        13055\n",
       "Full_Band_MelGan   1        13055\n",
       "HifiGan            1        13055\n",
       "MelGan             1        13055\n",
       "MelGanLarge        1        13055\n",
       "Multi_Band_MelGan  1        13055\n",
       "Parallel_WaveGan   1        13055\n",
       "Real               0        13055\n",
       "UberDuck           1        13055\n",
       "Waveglow           1        13055\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['architecture', 'label']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73bb9087-a587-4b7f-a270-031cf55bd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(data_df):\n",
    "    speaker_model = nemo_asr.models.EncDecSpeakerLabelModel.from_pretrained(model_name='titanet_large')\n",
    "    embedding_manager = AudioEmbeddingsManager(model=speaker_model, data=data_df)\n",
    "    em_feature_df, em_feature_cols = embedding_manager.generateFeatureDf()\n",
    "    \n",
    "    cadence_manager = CadenceModelManager(data_df)\n",
    "    cad_feature_df, cad_feature_cols, scalar =  cadence_manager.run_cadence_feature_extraction_pipeline(fill_na=-1) # Add param for load features or not\n",
    "    \n",
    "    smile_manager = SmileFeatureManager(data_df)\n",
    "    #change number of features (feature_count=10 default)\n",
    "    os_binary_feature_df, os_binary_feature_cols = smile_manager.generateFeatureDf('random_forest', label_type='binary', feature_count=20)\n",
    "    os_multiclass_feature_df, os_multiclass_feature_cols = smile_manager.generateFeatureDf('random_forest', label_type='multiclass', feature_count=20)\n",
    "    \n",
    "    feature_store = {}\n",
    "    feature_store['titanet'] = (em_feature_df, em_feature_cols)\n",
    "    feature_store['openSmile_binary'] = (os_binary_feature_df, os_binary_feature_cols)\n",
    "    feature_store['openSmile_multiclass'] = (os_multiclass_feature_df, os_multiclass_feature_cols)\n",
    "    feature_store['cadence'] = (cad_feature_df, cad_feature_cols)\n",
    "    \n",
    "    return feature_store\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f444f8df-6f02-4f76-869d-a8722e7c5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(feature_store, fake_cols):\n",
    "    results_cols = ['feature_method', 'model', 'fake_cols', 'label_type', 'acc', 'cls_acc', 'loss', 'eer_score', 'eer_threshold']\n",
    "    results = pd.DataFrame(columns=results_cols)\n",
    "    \n",
    "    models = ['logreg', 'random_forest']\n",
    "    for model in models:\n",
    "        for label_type in ['label', 'multiclass_label']:\n",
    "            for k, v in feature_store.items():\n",
    "                model_manager = ModelManager(model, v[0], v[1], merge_train_dev=True)\n",
    "                model_manager.trainPredict(label_col=label_type)\n",
    "                results = results.append(pd.DataFrame({'feature_method':[k], 'label_type':[label_type], 'fake_cols':[fake_cols], 'acc':[model_manager.accuracy], 'cls_acc':[model_manager.class_accuracy],  'loss':[model_manager.log_loss_value], 'model':[model], \n",
    "                                                       'eer_score':[model_manager.eer_score], 'eer_threshold':[model_manager.eer_threshold]}))\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c8a77a-0903-47d6-a059-9f4101f8cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fake_cols, metadata_path, name, data_df=None):\n",
    "    if data_df is None:\n",
    "        data_df = generate_split(fake_cols, metadata_path)\n",
    "    feature_store = generate_features(data_df)\n",
    "    results = train_eval(feature_store, fake_cols)\n",
    "    results.to_csv(f'/home/ubuntu/data/results/7-7-23/{name}.csv', index=False)\n",
    "    return results\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd29fdca-25a1-4e8f-a304-5c861c021cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = pd.DataFrame(columns=['feature_method', 'model', 'fake_cols', 'label_type', 'acc', 'cls_acc', 'loss', 'laundered', 'eer_score', 'eer_threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7da5b3-6cc2-4945-b028-b77a074181c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "results = run(['ElevenLabs'], file_path, '16KHz_ElevenLabs')\n",
    "results['laundered'] = 0\n",
    "agg_df = agg_df.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e192f-ea8d-457e-b4da-51ac17ff6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SB_Comment - where are the final uned cadence results? I can see the params used below but dont think they're being used \n",
    "## SB_Comment - should set the window size and threshold as global params e.g. uberduck_window_size, elevenlabs_window_size, general_window_size etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b5523-356f-4c93-8643-c8db29057b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "results = run(['UberDuck'], file_path, '16KHz_UberDuck')\n",
    "results['laundered'] = 0\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6fe04-b257-4df0-81c2-02608f068378",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "results = run(['RandWaveFake'], file_path, '16KHz_RandWaveFake_B')\n",
    "results['laundered'] = 0\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323a8b9-1d03-45f3-9161-f289f2795f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "results = run(['UberDuck', 'ElevenLabs'], file_path, '16KHz_ElevenLabs_and_UberDuck')\n",
    "results['laundered'] = 0\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95bd03da-e36e-4ce6-909c-d519188eb049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Train instances: 31332\n",
      "# of Dev instances: 10444\n",
      "# of Test instances: 10444\n",
      "[NeMo I 2023-07-07 10:26:07 cloud:56] Found existing object /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo.\n",
      "[NeMo I 2023-07-07 10:26:07 cloud:62] Re-using file from: /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo\n",
      "[NeMo I 2023-07-07 10:26:07 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-07-07 10:26:08 modelPT:156] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 3\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-07-07 10:26:08 modelPT:163] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    time_length: 3\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-07-07 10:26:08 label_models:126] Setting angular: true/false in decoder is deprecated and will be removed in 1.13 version, use specific loss with _target_\n",
      "[NeMo I 2023-07-07 10:26:08 features:267] PADDING: 16\n",
      "[NeMo I 2023-07-07 10:26:09 save_restore_connector:243] Model EncDecSpeakerLabelModel was successfully restored from /home/ubuntu/.cache/torch/NeMo/NeMo_1.15.0/titanet-l/492c0ab8416139171dc18c21879a9e45/titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 19.69it/s]\n",
      "100%|██████████| 4/4 [01:12<00:00, 18.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing data...\n",
      "Standardizing features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mElevenLabs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUberDuck\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRandWaveFake\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m16KHz_Mix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaundered\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m agg_df \u001b[38;5;241m=\u001b[39m agg_df\u001b[38;5;241m.\u001b[39mappend(results)\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(fake_cols, metadata_path, name, data_df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     data_df \u001b[38;5;241m=\u001b[39m generate_split(fake_cols, metadata_path)\n\u001b[0;32m----> 4\u001b[0m feature_store \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m train_eval(feature_store, fake_cols)\n\u001b[1;32m      6\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ubuntu/data/results/7-7-23/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mgenerate_features\u001b[0;34m(data_df)\u001b[0m\n\u001b[1;32m      9\u001b[0m smile_manager \u001b[38;5;241m=\u001b[39m SmileFeatureManager(data_df)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#change number of features (feature_count=10 default)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m os_binary_feature_df, os_binary_feature_cols \u001b[38;5;241m=\u001b[39m \u001b[43msmile_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerateFeatureDf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom_forest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m os_multiclass_feature_df, os_multiclass_feature_cols \u001b[38;5;241m=\u001b[39m smile_manager\u001b[38;5;241m.\u001b[39mgenerateFeatureDf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m'\u001b[39m, label_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     14\u001b[0m feature_store \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/MultiModalDeepFake/packages/SmileFeatureManager.py:72\u001b[0m, in \u001b[0;36mSmileFeatureManager.generateFeatureDf\u001b[0;34m(self, feature_selector_type, label_type, feature_count)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m label_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel type must be either binary or multiclass\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_selector_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m#GK edit 06/29/23 to set random state\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     selector \u001b[38;5;241m=\u001b[39m \u001b[43msmileFeatureSelectFromModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata_cols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     75\u001b[0m         df \u001b[38;5;241m=\u001b[39m  selector\u001b[38;5;241m.\u001b[39mselect_features_binary(max_features\u001b[38;5;241m=\u001b[39mfeature_count, return_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/MultiModalDeepFake/packages/SmileFeatureSelector.py:200\u001b[0m, in \u001b[0;36msmileFeatureSelectFromModel.__init__\u001b[0;34m(self, df, metadata, standardize, model)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03mInitialize the smileFeatureSelectorBruteForce class.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m#initialize the base class\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandardize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m#load the model to use for brute force feature selection\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[0;32m~/MultiModalDeepFake/packages/SmileFeatureSelector.py:178\u001b[0m, in \u001b[0;36msmileFeatureSelectorBase.__init__\u001b[0;34m(self, df, metadata, standardize)\u001b[0m\n\u001b[1;32m    176\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m    177\u001b[0m scaler\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df[cols_to_scale])\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols_to_scale\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df\u001b[38;5;241m.\u001b[39mloc[:, cols_to_scale])\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev_df\u001b[38;5;241m.\u001b[39mloc[:, cols_to_scale] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev_df\u001b[38;5;241m.\u001b[39mloc[:, cols_to_scale])\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df\u001b[38;5;241m.\u001b[39mloc[:, cols_to_scale] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_df\u001b[38;5;241m.\u001b[39mloc[:, cols_to_scale])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1834\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_2d_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1906\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1901\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1902\u001b[0m     )\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ilocs):\n\u001b[1;32m   1905\u001b[0m     \u001b[38;5;66;03m# setting with a list, re-coerces\u001b[39;00m\n\u001b[0;32m-> 1906\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1996\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   1994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1996\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;66;03m# We will not operate in-place, but will attempt to in the future.\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;66;03m#  To determine whether we need to issue a FutureWarning, see if the\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;66;03m#  setting in-place would work, i.e. behavior will change.\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_column_array(loc)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4152\u001b[0m, in \u001b[0;36mDataFrame._iset_item\u001b[0;34m(self, loc, value)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iset_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc: \u001b[38;5;28mint\u001b[39m, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4152\u001b[0m     arraylike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, arraylike, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n\u001b[1;32m   4156\u001b[0m     \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n\u001b[1;32m   4157\u001b[0m     \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4905\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4904\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m-> 4905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/construction.py:618\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    616\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 618\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "results = run(['ElevenLabs', 'UberDuck', 'RandWaveFake'], file_path, '16KHz_Mix')\n",
    "results['laundered'] = 0\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59f1ae-5207-4a9d-b292-25074edc4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "results = run(['EL_UD_Fake'], file_path, '16KHz_EL_UD_Fake_B')\n",
    "results['laundered'] = 0\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169055ad-6fef-4bf4-9ce8-a536286c55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16000KHz.csv'\n",
    "results = run(['Fake'], file_path, '16KHz_Fake')\n",
    "results['laundered'] = 0\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff1f08-e8c3-4531-bfd3-3cb455946e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "results = run(['ElevenLabs'], file_path, '16KHz_ElevenLabs_Laundered')\n",
    "results['laundered'] = 1\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06322cae-5e05-4df0-a309-d8b77dc96ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "results = run(['UberDuck'], file_path, '16KHz_UberDuck_Laundered')\n",
    "results['laundered'] = 1\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7012e3e-bcda-4cf6-a111-969771b768d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "results = run(['RandWaveFake'], file_path, '16KHz_RandWaveFake_Laundered')\n",
    "results['laundered'] = 1\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab235243-e6e4-4d01-a91d-9e9ed45eecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "results = run(['UberDuck', 'ElevenLabs'], file_path, '16KHz_ElevenLabs_and_UberDuck_Laundered')\n",
    "results['laundered'] = 1\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b87d4-d366-48de-9c5f-f0648069f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "results = run(['ElevenLabs', 'UberDuck', 'RandWaveFake'], file_path, '16KHz_Mix_Laundered')\n",
    "results['laundered'] = 1\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722812eb-90c7-43a3-b0f2-9131167bcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "results = run(['EL_UD_Fake'], file_path, '16KHz_EL_UD_Fake_Laundered_B')\n",
    "results['laundered'] = 1\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/ubuntu/data/wavefake_data/LJ_metadata_16KHz_Laundered.csv'\n",
    "results = run(['Fake'], file_path, '16KHz_Fake_Laundered_B')\n",
    "results['laundered'] = 1\n",
    "agg_df = agg_df.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.to_csv('/home/ubuntu/data/results/6-30-23/agg_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = '/home/ubuntu/data/TIMIT converted/wav_files'\n",
    "file_count = len(list(os.listdir(directory)))\n",
    "file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb509735-d0da-4cd3-9d2f-5cc28c61be49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nemo",
   "language": "python",
   "name": "nemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
