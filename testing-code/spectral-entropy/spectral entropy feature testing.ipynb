{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a7eb20",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e072803",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99139ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10cdc0e",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec49dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307c28f-dbed-410f-a8c9-a4145d27cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4dfea7-7516-44c1-abc6-6ba146b23ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb3d96-e7ef-46f4-a354-654cd6f38d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8be67-b3e5-4994-9d12-98dde4477bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb018f71-5e17-4488-9271-d27954fdb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d896575-84b6-4b0e-8448-38795daa383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616af0b",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d7463",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0713f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be114e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d10075",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1252d1f5-2d33-465b-9530-34abe82d7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76eb2ac-d159-4414-be77-5a250a62c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f12cc9",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df04163",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21178465",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7449506",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f826f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b81ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61566344",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a23cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0937602",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a24e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70dd6fdf",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8ed9f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec263c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17029e6d",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d678108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb77e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2594950",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7a5fe",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1582bb",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85520de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b0fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d21787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bcf830",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7aa2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616dd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19968f2",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00faab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f277159",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30967480",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085809be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ed8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc168b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22212142",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1b050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eef4ae7",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a2604",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ca450",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e01ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8943d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea59cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69686d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1234c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91628cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ed148",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3259ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697890d",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490ccad",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ae3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3add4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd81f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddd5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebdda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e4893",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926cec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7578df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aee282",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087813df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c113e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a494c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff597b04",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce04021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343744a",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b39699",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a449be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c83eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78789408",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c2fda",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42efb32e",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5daa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3803ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2649f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ddbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82528188",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433361d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef370f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b281dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16634293",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2facea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f40080",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13232e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a12099",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9130ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14018706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28054537",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3da20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c616ecc6",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f2f75",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7df12",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1072b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52200708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a04585",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf15690",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43583bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20168895",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23158daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5538ccc",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019af545",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecae2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dfc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe69f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69935dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e19b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196a174",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a699ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e0426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaff6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a56f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5490e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d902696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae45a285",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b88288",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fcea3b",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ac30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc29543",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99542dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d8392",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a64eb",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be187fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20394db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d348b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfef8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82aa99",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a06067",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab19557",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a06121",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cd20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b111f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89900e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b20dec68",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba132ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740542f6",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb32bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c331be6",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cde04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf19fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d60974",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fe704",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8561fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d2306",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d2a97",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadf1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce934b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945469df",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b842d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd5e20",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241efa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090181a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d593ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fab5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb884505",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854db28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ae91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfe8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5cff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe003a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "820c5e15",
   "metadata": {},
   "source": [
    "# Spectral Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29ddad",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/ubuntu/\"\n",
    "\n",
    "biden_ai = base_path + 'data/world-leaders-dataset/biden_ai.wav'\n",
    "biden_real = base_path + 'data/world-leaders-dataset/biden_original.wav'\n",
    "\n",
    "timit_real = base_path + 'data/timit-test/example_real_resampled.wav'\n",
    "timit_og_real = base_path + 'data/timit-test/example_real_original.wav'\n",
    "timit_fake = base_path + 'data/timit-test/example_fake_resampled.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecee38",
   "metadata": {},
   "source": [
    "## Extract F0\n",
    "\n",
    "Reference: https://librosa.org/doc/main/generated/librosa.pyin.html\n",
    "\n",
    "- __f0:__ time series of fundamental frequencies in Hertz\n",
    "\n",
    "- __voiced_flag:__ time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "- __voiced_prob:__ time series containing the probability that a frame is voiced.\n",
    "\n",
    "The min and max frequencies passed as params while extracting F0 recommended by librosa are 'C2' ~65 hz and 'C7' ~2093 hz.\n",
    "\n",
    "The voiced speech of a typical adult male will have a fundamental frequency from 85 to 155 Hz, and that of a typical adult female from 165 to 255 Hz. [Voice frequency](https://en.wikipedia.org/wiki/Voice_frequency). \n",
    "\n",
    "Function returns `nan` values whenever there is no voiced segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ca56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_f0_sequence(audio_file, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #use pYIN to extract f0 and voiced segment flag + probaility\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(audio, fmin=fmin, \n",
    "                                                 fmax=fmax, fill_na=np.nan)\n",
    "    \n",
    "    #generate ndarray of times (in seconds) corresponding to each frame of X\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    return f0, times, voiced_flag, voiced_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfec767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f0_spectrogram(audio_file, f0_sequence, f0_times):\n",
    "    \n",
    "    #load the audio file\n",
    "    audio, sr = librosa.load(audio_file)\n",
    "    \n",
    "    #generate spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    #plot spectrogram from stft\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    img = librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "    ax.set(title='pYIN fundamental frequency estimation')\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    #overlay f0 sequence\n",
    "    ax.plot(f0_times, f0_sequence, label='f0', color='cyan', linewidth=3)\n",
    "    ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_jbreal, times_jb_real, _, _ = extract_f0_sequence(biden_real) \n",
    "f0_jbfake, times_jb_fake, _, _ = extract_f0_sequence(biden_ai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_real, f0_jbreal, times_jb_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(biden_ai, f0_jbfake, times_jb_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_timit_real, times_timit_real, _, _ = extract_f0_sequence(timit_real)\n",
    "f0_timit_og_real, times_timit_og_real, _, _ = extract_f0_sequence(timit_og_real) \n",
    "f0_timit_fake, times_timit_fake, _, _ = extract_f0_sequence(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_real, f0_timit_real, times_timit_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_og_real, f0_timit_og_real, times_timit_og_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eddee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(timit_fake, f0_timit_fake, times_timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b416123",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-6])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273598e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(timit_fake)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e66dad",
   "metadata": {},
   "source": [
    "## Spectral Entropy:\n",
    "\n",
    "References:\n",
    "- https://kilthub.cmu.edu/articles/thesis/Audio_Deepfake_Detection_Based_on_Differences_in_Human_and_Machine_Generated_Speech/21842454\n",
    "\n",
    "- https://dsp.stackexchange.com/questions/23689/what-is-spectral-entropy\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1239d3",
   "metadata": {},
   "source": [
    "__Notes:__\n",
    "\n",
    "- Typically PSD is computed using a periodogram. Is it OK to use an STFT for the audio signal?\n",
    "- stft output is `freq_bins * frames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_real)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d80f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(biden_ai)\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-7])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1bebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_entropy(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    normalized_psd = psd/np.sum(psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs to be reviewed\n",
    "def compute_spectral_entropy_f0(audio_file):\n",
    "    \n",
    "    audio_ts, sr = librosa.load(audio_file)\n",
    "    \n",
    "    freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "    \n",
    "    f0_sequence, _, _, _ = extract_f0_sequence(audio_file)\n",
    "    \n",
    "    f0_psd = np.zeros(len(f0_sequence))\n",
    "    \n",
    "    for i,f0 in enumerate(f0_sequence):\n",
    "        if np.isnan(f0):\n",
    "            f0_psd[i]=0\n",
    "        else:\n",
    "            difference_array = np.abs(freqs-f0)\n",
    "            index = difference_array.argmin()\n",
    "            f0_psd[i] = psd[index]\n",
    "    \n",
    "    normalized_f0_psd = f0_psd/np.sum(f0_psd)\n",
    "    \n",
    "    spectral_entropy = scipy.stats.entropy(normalized_f0_psd)\n",
    "    \n",
    "    return spectral_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(biden_real), compute_spectral_entropy(biden_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bfff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffd46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(timit_real), compute_spectral_entropy(timit_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c14f40",
   "metadata": {},
   "source": [
    "## Testing for LibriSpeech and generated versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8797b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LJ_original = '/Users/gautham/datasets/wavefake_data/LJSpeech_1.1/wavs'\n",
    "\n",
    "LJ_fbmelgan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_full_band_melgan'\n",
    "\n",
    "LJ_parallel_wavegan = '/Users/gautham/datasets/wavefake_data/generated_audio/ljspeech_parallel_wavegan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_original):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            original_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "original_files.sort()\n",
    "print(len(original_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3955df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "melgan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_fbmelgan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            melgan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "melgan_files.sort()\n",
    "print(len(melgan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavegan_files = []\n",
    "for dirpath,_,filenames in os.walk(LJ_parallel_wavegan):\n",
    "    for file in filenames:\n",
    "        if file.startswith(\"LJ001-\") and file.endswith('.wav'):\n",
    "        #if file.endswith('.wav'):\n",
    "            wavegan_files.append(os.path.abspath(os.path.join(dirpath, file)))\n",
    "wavegan_files.sort()\n",
    "print(len(wavegan_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy(original_files[0]), compute_spectral_entropy(melgan_files[0]), compute_spectral_entropy(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_spectral_entropy_f0(original_files[0]), compute_spectral_entropy_f0(melgan_files[0]), compute_spectral_entropy_f0(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files_entropy = [compute_spectral_entropy(file) for file in original_files]\n",
    "melgan_files_entropy = [compute_spectral_entropy(file) for file in melgan_files]\n",
    "wavegan_files_entropy = [compute_spectral_entropy(file) for file in wavegan_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "sns.kdeplot(original_files_entropy, label='original')\n",
    "sns.kdeplot(melgan_files_entropy, label='melgan')\n",
    "sns.kdeplot(wavegan_files_entropy, label='wavegan')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3731dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_orig, times_orig, _, _ = extract_f0_sequence(original_files[0]) \n",
    "f0_melgan, times_melgan, _, _ = extract_f0_sequence(melgan_files[0])\n",
    "f0_wavegan, times_wavegan, _, _ = extract_f0_sequence(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_files[0])\n",
    "print(melgan_files[0])\n",
    "print(wavegan_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(original_files[0], f0_orig, times_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5685234",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(melgan_files[0], f0_melgan, times_melgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7303b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f0_spectrogram(wavegan_files[0], f0_wavegan, times_wavegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(original_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3af54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(melgan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ts, sr = librosa.load(wavegan_files[0])\n",
    "freqs, psd = scipy.signal.periodogram(audio_ts, sr, nfft=2048)\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.semilogy(freqs, psd)\n",
    "plt.ylim([1e-18, 1e-3])\n",
    "plt.xticks(np.arange(0,12000,1000))\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40ab5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-detection-v1",
   "language": "python",
   "name": "deepfake-detection-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
